from abc import abstractmethod
from evalset.test_funcs import TestFunction, lzip
import numpy

from timeit import default_timer as now


class MulticriteriaTestFunction(TestFunction):
    """
    This class is designed to minimize multiple functions which accept vectors of size dim and then return vectors of
    size output_dim.  These vectors contain competing metrics (a decrease in one may cause an increase in the other)
    and thus optimization yields not a single point but rather a so-called Pareto frontier of efficient points.

    fmin and fmax now contain the elementwise min and max of the component functions; min_loc is a 2D array containing
    the locations that yield those fmin values.  There is also a new solution member, frontier, which contains an
    approximation to the true frontier derived from a brute force computation.  metric_names is unneeded (as it can
    simply be f1, f2, ...) but is put here to allow flexibility in naming going forward.

    For expediency, duplicate points can exist in the frontier; these could be removed with a bit of work.
    """

    def __init__(self, dim, verify):
        super(MulticriteriaTestFunction, self).__init__(dim, verify)
        self.frontier = None
        self.metric_names = ['f1', 'f2']  # Enforcing this for right now, but can be more flexible later
        self.output_dim = 2

    def evaluate(self, x):
        if self.verify and (not isinstance(x, numpy.ndarray) or x.shape != (self.dim,)):
            raise ValueError('Argument must be a numpy array of length {}'.format(self.dim))

        self.num_evals += 1
        value = self.do_evaluate(x)
        self.update_records(now(), x, value)
        return value

    def do_evaluate(self, x):
        return numpy.array([self.component_functions(d, x) for d in range(self.output_dim)])

    def component_functions(self, d, x):
        assert int(d) == d and 0 <= d < self.output_dim, 'Unacceptable dimension {0} {1}'.format(d, self.output_dim)
        return self.do_component_function(d, x)

    @abstractmethod
    def do_component_function(self, d, x):
        """
        :param d: dimension of the output for which to evaluate
        :type d: int, 0 <= d < self.output_dim
        :param x: point at which to evaluate the function
        :type x: numpy.array with shape (self.dim, )
        """
        raise NotImplementedError


class MCMcCourt01(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(MCMcCourt01, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[.5, -.4], [0, .2]])
        self.fmin = numpy.array([0, -2])
        self.fmax = numpy.array([4.21, -0.510783476247])
        self.frontier = numpy.array([
            [0.138, -1.794], [0.552, -1.998], [0.384, -1.969], [0.213, -1.876], [0.083, -1.700], [0.562, -1.999],
            [0.172, -1.835], [0.039, -1.585], [0.299, -1.934], [0.272, -1.918], [0.139, -1.795], [0.451, -1.986],
            [0.037, -1.583], [0.116, -1.762], [0.059, -1.646], [0.000, -1.341], [0.010, -1.458], [0.326, -1.948],
            [0.278, -1.923], [0.512, -1.995], [0.074, -1.678], [0.595, -2.000], [0.404, -1.975], [0.024, -1.532],
            [0.087, -1.707], [0.064, -1.657], [0.182, -1.847], [0.043, -1.603], [0.312, -1.941], [0.310, -1.939],
            [0.227, -1.888], [0.436, -1.982], [0.100, -1.732], [0.391, -1.970], [0.026, -1.542], [0.130, -1.781],
            [0.233, -1.890], [0.070, -1.673], [0.001, -1.375], [0.015, -1.493], [0.153, -1.814], [0.298, -1.933],
            [0.044, -1.604], [0.143, -1.799], [0.447, -1.984], [0.185, -1.847], [0.075, -1.683], [0.530, -1.997],
            [0.353, -1.959], [0.214, -1.876], [0.271, -1.914], [0.262, -1.912], [0.484, -1.992], [0.422, -1.979],
            [0.094, -1.723], [0.052, -1.627], [0.003, -1.405], [0.169, -1.831], [0.332, -1.950], [0.055, -1.637],
            [0.570, -1.999], [0.360, -1.961], [0.211, -1.873], [0.020, -1.514], [0.083, -1.703], [0.016, -1.497],
            [0.152, -1.811], [0.272, -1.919], [0.125, -1.776], [0.450, -1.986], [0.042, -1.599], [0.105, -1.743],
            [0.228, -1.888], [0.067, -1.667], [0.000, -1.357], [0.490, -1.993], [0.007, -1.435], [0.323, -1.946],
            [0.190, -1.854], [0.257, -1.909], [0.064, -1.653], [0.162, -1.821], [0.132, -1.782], [0.393, -1.972],
            [0.170, -1.832], [0.097, -1.728], [0.175, -1.839], [0.040, -1.591], [0.303, -1.937], [0.246, -1.902],
            [0.107, -1.744], [0.005, -1.418], [0.233, -1.891], [0.018, -1.509], [0.119, -1.765], [0.002, -1.378],
            [0.011, -1.469], [0.365, -1.962], [0.155, -1.816], [0.322, -1.943], [0.291, -1.930], [0.049, -1.619],
            [0.159, -1.818], [0.412, -1.977], [0.033, -1.566], [0.065, -1.659], [0.525, -1.996], [0.011, -1.467],
            [0.356, -1.960], [0.194, -1.859], [0.028, -1.543], [0.266, -1.913], [0.261, -1.910], [0.478, -1.991],
            [0.116, -1.760], [0.616, -2.000], [0.419, -1.979], [0.028, -1.552], [0.095, -1.725], [0.057, -1.641],
            [0.050, -1.621], [0.331, -1.950], [0.002, -1.386], [0.149, -1.806], [0.541, -1.997], [0.212, -1.875],
            [0.021, -1.516], [0.020, -1.512], [0.360, -1.961], [0.284, -1.923], [0.462, -1.988], [0.199, -1.859],
            [0.034, -1.572], [0.338, -1.950], [0.114, -1.758], [0.067, -1.666], [0.000, -1.321], [0.488, -1.992],
            [0.007, -1.438], [0.347, -1.956], [0.275, -1.921], [0.580, -2.000], [0.392, -1.972], [0.031, -1.560],
            [0.083, -1.701], [0.400, -1.973], [0.177, -1.841], [0.041, -1.596], [0.305, -1.937], [0.229, -1.889],
            [0.108, -1.748], [0.002, -1.382], [0.021, -1.521], [0.080, -1.697], [0.001, -1.363], [0.013, -1.480],
            [0.150, -1.810], [0.297, -1.931], [0.001, -1.364], [0.137, -1.790], [0.426, -1.981], [0.091, -1.713],
            [0.193, -1.857], [0.099, -1.732], [0.535, -1.997], [0.355, -1.960], [0.205, -1.868], [0.251, -1.905],
            [0.472, -1.989], [0.124, -1.773], [0.612, -2.000], [0.029, -1.554], [0.102, -1.738], [0.048, -1.618],
            [0.006, -1.429], [0.156, -1.816], [0.256, -1.908], [0.061, -1.650], [0.378, -1.968], [0.220, -1.882],
            [0.017, -1.502], [0.082, -1.700], [0.012, -1.476], [0.381, -1.969], [0.164, -1.826], [0.035, -1.574],
            [0.288, -1.928], [0.078, -1.686], [0.140, -1.797], [0.437, -1.983], [0.040, -1.594], [0.116, -1.760],
            [0.059, -1.648], [0.000, -1.347], [0.521, -1.996], [0.010, -1.464], [0.185, -1.848], [0.276, -1.921],
            [0.506, -1.994], [0.127, -1.776], [0.423, -1.980], [0.088, -1.711], [0.192, -1.856], [0.048, -1.616],
            [0.325, -1.947], [0.310, -1.938], [0.238, -1.896], [0.102, -1.733], [0.003, -1.398], [0.219, -1.880],
            [0.022, -1.524], [0.134, -1.787], [0.071, -1.676], [0.001, -1.366], [0.014, -1.484], [0.152, -1.812],
            [0.311, -1.940], [0.045, -1.609], [0.147, -1.803], [0.092, -1.717], [0.032, -1.564], [0.071, -1.676],
            [0.532, -1.997], [0.012, -1.469], [0.370, -1.965], [0.207, -1.869], [0.249, -1.903], [0.465, -1.989],
            [0.109, -1.750],
        ])
        self.classifiers = ['unimodal']

    def do_component_function(self, d, x):
        x1, x2 = x
        if d == 0:
            return (x1 - .5) ** 2 + (x2 + .4) ** 2
        else:
            return -(numpy.sin(2 * x1) / (2 * x1) if abs(x1) > 1e-13 else 1.0) - numpy.exp(-2 * (x2 - .2) ** 2)


class MCMcCourt02(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(MCMcCourt02, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[0.60065187, -0.49739315], [-1, -1]])
        self.fmin = numpy.array([-0.602649847736, -2.21986579198])
        self.fmax = numpy.array([-0.000256097326268, 0])
        self.frontier = numpy.array([
            [-0.505, -0.968], [-0.023, -2.122], [-0.574, -0.893], [-0.199, -1.900], [-0.404, -1.734], [-0.498, -1.592],
            [-0.451, -1.687], [-0.201, -1.897], [-0.602, -0.010], [-0.084, -2.014], [-0.295, -1.822], [-0.173, -1.920],
            [-0.518, -0.957], [-0.588, -0.861], [-0.322, -1.799], [-0.533, -0.942], [-0.394, -1.742], [-0.427, -1.710],
            [-0.062, -2.039], [-0.598, -0.845], [-0.015, -2.156], [-0.468, -1.663], [-0.227, -1.874], [-0.275, -1.833],
            [-0.109, -1.985], [-0.488, -1.628], [-0.030, -2.104], [-0.549, -0.920], [-0.192, -1.905], [-0.374, -1.758],
            [-0.568, -0.904], [-0.231, -1.872], [-0.420, -1.719], [-0.079, -2.018], [-0.291, -1.825], [-0.144, -1.946],
            [-0.493, -1.616], [-0.188, -1.909], [-0.342, -1.785], [-0.495, -1.613], [-0.476, -1.654], [-0.596, -0.847],
            [-0.285, -1.830], [-0.123, -1.973], [-0.511, -0.962], [-0.027, -2.105], [-0.580, -0.887], [-0.158, -1.936],
            [-0.547, -0.929], [-0.387, -1.748], [-0.208, -1.890], [-0.602, -0.013], [-0.164, -1.932], [-0.349, -1.779],
            [-0.272, -1.838], [-0.600, -0.825], [-0.009, -2.184], [-0.255, -1.854], [-0.272, -1.835], [-0.491, -1.625],
            [-0.020, -2.133], [-0.224, -1.879], [-0.380, -1.755], [-0.500, -1.583], [-0.579, -0.888], [-0.437, -1.700],
            [-0.601, -0.017], [-0.103, -1.989], [-0.327, -1.797], [-0.509, -0.962], [-0.527, -0.949], [-0.150, -1.945],
            [-0.536, -0.935], [-0.416, -1.723], [-0.404, -1.732], [-0.052, -2.061], [-0.475, -1.656], [-0.238, -1.866],
            [-0.600, -0.826], [-0.101, -1.995], [-0.479, -1.648], [-0.031, -2.097], [-0.196, -1.902], [-0.560, -0.914],
            [-0.383, -1.749], [-0.242, -1.864], [-0.447, -1.692], [-0.083, -2.015], [-0.294, -1.823], [-0.498, -1.595],
            [-0.503, -0.970], [-0.166, -1.930], [-0.373, -1.760], [-0.455, -1.683], [-0.206, -1.894], [-0.591, -0.859],
            [-0.256, -1.852], [-0.141, -1.953], [-0.185, -1.911], [-0.545, -0.931], [-0.360, -1.769], [-0.233, -1.870],
            [-0.071, -2.029], [-0.325, -1.798], [-0.173, -1.924], [-0.334, -1.792], [-0.421, -1.716], [-0.038, -2.085],
            [-0.258, -1.849], [-0.186, -1.910], [-0.532, -0.945], [-0.053, -2.049], [-0.424, -1.715], [-0.596, -0.851],
            [-0.280, -1.832], [-0.148, -1.946], [-0.458, -1.679], [-0.599, -0.833], [-0.337, -1.787], [-0.030, -2.100],
            [-0.562, -0.912], [-0.094, -2.001], [-0.244, -1.862], [-0.155, -1.941], [-0.296, -1.822], [-0.479, -1.650],
            [-0.389, -1.746], [-0.194, -1.905], [-0.502, -0.971], [-0.077, -2.019], [-0.389, -1.747], [-0.584, -0.881],
            [-0.018, -2.143], [-0.127, -1.968], [-0.495, -1.611], [-0.345, -1.783], [-0.010, -2.182], [-0.540, -0.934],
            [-0.085, -2.007], [-0.602, -0.010], [-0.456, -1.682], [-0.020, -2.131], [-0.428, -1.706], [-0.480, -1.639],
            [-0.359, -1.772], [-0.536, -0.939], [-0.093, -2.005], [-0.571, -0.898], [-0.238, -1.868], [-0.170, -1.925],
            [-0.472, -1.658], [-0.053, -2.046], [-0.489, -1.625], [-0.519, -0.955], [-0.066, -2.039], [-0.114, -1.981],
            [-0.426, -1.713], [-0.263, -1.847], [-0.602, -0.008], [-0.487, -1.634], [-0.362, -1.767], [-0.197, -1.901],
            [-0.523, -0.953], [-0.053, -2.055], [-0.413, -1.726], [-0.200, -1.899], [-0.293, -1.823], [-0.137, -1.957],
            [-0.449, -1.689], [-0.350, -1.778], [-0.555, -0.915], [-0.570, -0.902], [-0.251, -1.856], [-0.306, -1.813],
            [-0.472, -1.660], [-0.035, -2.094], [-0.172, -1.924], [-0.399, -1.737], [-0.594, -0.857], [-0.253, -1.854],
            [-0.132, -1.959], [-0.297, -1.813], [-0.497, -1.603], [-0.313, -1.808], [-0.039, -2.083], [-0.529, -0.946],
            [-0.175, -1.919], [-0.043, -2.077], [-0.601, -0.015], [-0.446, -1.692], [-0.217, -1.883], [-0.025, -2.112],
            [-0.130, -1.966], [-0.438, -1.699], [-0.268, -1.841], [-0.382, -1.753], [-0.584, -0.865], [-0.214, -1.887],
            [-0.564, -0.910], [-0.374, -1.758], [-0.581, -0.886], [-0.464, -1.669], [-0.224, -1.879], [-0.013, -2.162],
            [-0.317, -1.803], [-0.156, -1.940], [-0.336, -1.787], [-0.485, -1.635], [-0.360, -1.769], [-0.176, -1.914],
            [-0.118, -1.973], [-0.431, -1.705], [-0.290, -1.826],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2 = x
            return -(
                .5 * numpy.exp(-10 * ((x1 + .8) ** 2 + (x2 + .6) ** 2)) +
                .5 * numpy.exp(-9 * ((x1 + .7) ** 2 + (x2 - .4) ** 2)) +
                .6 * numpy.exp(-11 * ((x1 - .6) ** 2 + (x2 + .5) ** 2)) +
                .6 * numpy.exp(-8 * ((x1 - .8) ** 2 + (x2 - .3) ** 2))
            )
        else:
            return -numpy.linalg.norm(x - self.min_loc[0])


class MCMcCourt03(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(MCMcCourt03, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[-0.71086527, 0.34990005], [1, -1]])
        self.fmin = numpy.array([-0.634069694159, -2.17928660737])
        self.fmax = numpy.array([-0.0327929364261, 0])
        self.frontier = numpy.array([
            [-0.442, -1.922], [-0.633, -0.020], [-0.141, -2.137], [-0.534, -1.803], [-0.633, -0.027], [-0.616, -1.636],
            [-0.549, -1.781], [-0.455, -1.905], [-0.571, -1.743], [-0.457, -1.898], [-0.495, -1.856], [-0.119, -2.162],
            [-0.620, -1.622], [-0.305, -2.031], [-0.496, -1.854], [-0.434, -1.932], [-0.607, -1.663], [-0.541, -1.793],
            [-0.631, -0.041], [-0.628, -1.581], [-0.606, -1.671], [-0.585, -1.717], [-0.562, -1.757], [-0.632, -0.039],
            [-0.451, -1.912], [-0.541, -1.793], [-0.510, -1.838], [-0.131, -2.154], [-0.620, -1.627], [-0.465, -1.892],
            [-0.561, -1.763], [-0.633, -0.022], [-0.175, -2.114], [-0.629, -1.554], [-0.531, -1.808], [-0.633, -0.025],
            [-0.614, -1.648], [-0.475, -1.880], [-0.221, -2.082], [-0.625, -1.600], [-0.592, -1.705], [-0.409, -1.958],
            [-0.490, -1.860], [-0.630, -0.051], [-0.590, -1.706], [-0.488, -1.866], [-0.527, -1.814], [-0.352, -1.993],
            [-0.579, -1.728], [-0.610, -1.660], [-0.562, -1.760], [-0.448, -1.915], [-0.244, -2.069], [-0.567, -1.752],
            [-0.468, -1.886], [-0.588, -1.710], [-0.631, -0.044], [-0.512, -1.834], [-0.618, -1.632], [-0.314, -2.021],
            [-0.481, -1.875], [-0.604, -1.673], [-0.539, -1.794], [-0.632, -0.033], [-0.602, -1.682], [-0.581, -1.727],
            [-0.472, -1.886], [-0.214, -2.084], [-0.501, -1.848], [-0.124, -2.154], [-0.624, -1.604], [-0.259, -2.061],
            [-0.571, -1.746], [-0.476, -1.880], [-0.452, -1.911], [-0.630, -0.047], [-0.545, -1.787], [-0.628, -1.563],
            [-0.608, -1.662], [-0.516, -1.828], [-0.329, -2.013], [-0.611, -1.658], [-0.627, -1.586], [-0.587, -1.715],
            [-0.419, -1.947], [-0.499, -1.849], [-0.595, -1.696], [-0.285, -2.034], [-0.584, -1.719], [-0.481, -1.874],
            [-0.633, -0.018], [-0.152, -2.133], [-0.539, -1.797], [-0.350, -2.002], [-0.562, -1.752], [-0.616, -1.640],
            [-0.447, -1.915], [-0.573, -1.743], [-0.504, -1.845], [-0.617, -1.632], [-0.497, -1.854], [-0.425, -1.942],
            [-0.602, -1.674], [-0.632, -0.036], [-0.171, -2.120], [-0.629, -1.560], [-0.601, -1.684], [-0.374, -1.980],
            [-0.632, -0.037], [-0.457, -1.904], [-0.623, -1.606], [-0.414, -1.949], [-0.523, -1.819], [-0.620, -1.627],
            [-0.268, -2.052], [-0.575, -1.737], [-0.467, -1.892], [-0.431, -1.936], [-0.552, -1.776], [-0.634, -0.004],
            [-0.189, -2.101], [-0.524, -1.818], [-0.506, -1.839], [-0.614, -1.647], [-0.473, -1.884], [-0.611, -1.652],
            [-0.626, -1.594], [-0.592, -1.704], [-0.483, -1.869], [-0.629, -0.056], [-0.592, -1.704], [-0.625, -1.601],
            [-0.283, -2.045], [-0.576, -1.731], [-0.488, -1.865], [-0.450, -1.912], [-0.525, -1.814], [-0.531, -1.809],
            [-0.359, -1.993], [-0.612, -1.650], [-0.555, -1.771], [-0.439, -1.926], [-0.561, -1.761], [-0.628, -1.568],
            [-0.381, -1.978], [-0.632, -0.033], [-0.502, -1.847], [-0.116, -2.169], [-0.490, -1.862], [-0.554, -1.773],
            [-0.631, -0.047], [-0.156, -2.127], [-0.628, -1.566], [-0.597, -1.695], [-0.576, -1.736], [-0.634, -0.006],
            [-0.465, -1.895], [-0.532, -1.806], [-0.200, -2.097], [-0.622, -1.614], [-0.396, -1.968], [-0.510, -1.838],
            [-0.136, -2.142], [-0.622, -1.614], [-0.441, -1.924], [-0.547, -1.785], [-0.629, -1.562], [-0.518, -1.826],
            [-0.333, -2.005], [-0.605, -1.673], [-0.464, -1.896],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2 = x
            return -(
                .6 * numpy.exp(-10 * ((x1 + .8) ** 2 + .3 * (x2 + .6) ** 2)) +
                .6 * numpy.exp(-9 * (.4 * (x1 + .7) ** 2 + .4 * (x2 - .4) ** 2)) +
                .6 * numpy.exp(-11 * (.2 * (x1 - .6) ** 2 + .5 * (x2 + .5) ** 2)) +
                .6 * numpy.exp(-8 * (.3 * (x1 - .8) ** 2 + .6 * (x2 - .3) ** 2))
            )
        else:
            return -numpy.linalg.norm(x - self.min_loc[0])


class MCMcCourt04(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(MCMcCourt04, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[0.02080787, -0.01383469], [-1, 1]])
        self.fmin = numpy.array([-0.694918380503, -1.4387180009])
        self.fmax = numpy.array([-0.0505587904118, 0])
        self.frontier = numpy.array([
            [-0.599, -0.857], [-0.397, -1.222], [-0.536, -0.921], [-0.695, -0.003], [-0.461, -1.148], [-0.508, -1.069],
            [-0.670, -0.746], [-0.561, -0.899], [-0.296, -1.335], [-0.366, -1.261], [-0.478, -1.123], [-0.525, -1.007],
            [-0.595, -0.863], [-0.424, -1.196], [-0.692, -0.030], [-0.682, -0.690], [-0.376, -1.250], [-0.553, -0.906],
            [-0.639, -0.805], [-0.495, -1.090], [-0.690, -0.035], [-0.685, -0.058], [-0.579, -0.879], [-0.297, -1.335],
            [-0.392, -1.232], [-0.472, -1.132], [-0.617, -0.836], [-0.694, -0.010], [-0.648, -0.792], [-0.431, -1.186],
            [-0.339, -1.289], [-0.263, -1.367], [-0.319, -1.310], [-0.656, -0.778], [-0.512, -1.056], [-0.276, -1.358],
            [-0.403, -1.219], [-0.437, -1.177], [-0.505, -1.073], [-0.681, -0.698], [-0.606, -0.850], [-0.326, -1.303],
            [-0.363, -1.264], [-0.541, -0.916], [-0.476, -1.128], [-0.525, -1.011], [-0.555, -0.904], [-0.230, -1.399],
            [-0.420, -1.201], [-0.687, -0.053], [-0.675, -0.730], [-0.107, -1.427], [-0.496, -1.088], [-0.359, -1.268],
            [-0.299, -1.331], [-0.345, -1.282], [-0.632, -0.817], [-0.498, -1.088], [-0.527, -0.988], [-0.545, -0.912],
            [-0.693, -0.023], [-0.446, -1.170], [-0.683, -0.672], [-0.673, -0.736], [-0.516, -1.042], [-0.569, -0.889],
            [-0.287, -1.345], [-0.383, -1.242], [-0.663, -0.760], [-0.439, -1.170], [-0.490, -1.104], [-0.581, -0.876],
            [-0.269, -1.360], [-0.636, -0.809], [-0.694, -0.019], [-0.368, -1.253], [-0.528, -0.929], [-0.302, -1.329],
            [-0.645, -0.798], [-0.505, -1.074], [-0.462, -1.146], [-0.515, -1.049], [-0.679, -0.711], [-0.239, -1.392],
            [-0.588, -0.870], [-0.314, -1.316], [-0.387, -1.239], [-0.465, -1.144], [-0.607, -0.849], [-0.447, -1.167],
            [-0.357, -1.271], [-0.267, -1.366], [-0.333, -1.293], [-0.660, -0.769], [-0.368, -1.254], [-0.437, -1.180],
            [-0.510, -1.058], [-0.611, -0.843], [-0.324, -1.305], [-0.314, -1.311], [-0.642, -0.802], [-0.486, -1.111],
            [-0.518, -1.039], [-0.562, -0.896], [-0.249, -1.381], [-0.692, -0.028], [-0.662, -0.763], [-0.396, -1.228],
            [-0.684, -0.061], [-0.276, -1.353], [-0.404, -1.217], [-0.347, -1.280], [-0.638, -0.808], [-0.499, -1.088],
            [-0.448, -1.165], [-0.533, -0.924], [-0.695, -0.002], [-0.515, -1.051], [-0.669, -0.750], [-0.579, -0.880],
            [-0.303, -1.328], [-0.384, -1.242], [-0.258, -1.375], [-0.489, -1.107], [-0.526, -1.003], [-0.591, -0.868],
            [-0.625, -0.824], [-0.427, -1.193], [-0.690, -0.039], [-0.682, -0.695], [-0.601, -0.853], [-0.538, -0.919],
            [-0.317, -1.310], [-0.650, -0.789], [-0.453, -1.155], [-0.216, -1.409], [-0.426, -1.193], [-0.521, -1.032],
            [-0.595, -0.860], [-0.306, -1.324], [-0.402, -1.222], [-0.628, -0.820], [-0.466, -1.141], [-0.614, -0.840],
            [-0.693, -0.021], [-0.430, -1.189], [-0.487, -1.108], [-0.266, -1.366], [-0.328, -1.301], [-0.663, -0.762],
            [-0.509, -1.063], [-0.576, -0.880], [-0.688, -0.044], [-0.449, -1.161], [-0.502, -1.081], [-0.680, -0.705],
            [-0.619, -0.835], [-0.342, -1.287], [-0.350, -1.278], [-0.468, -1.139], [-0.523, -1.021], [-0.573, -0.887],
            [-0.412, -1.210], [-0.687, -0.053], [-0.679, -0.713], [-0.220, -1.408], [-0.363, -1.265], [-0.294, -1.336],
            [-0.688, -0.049], [-0.528, -0.972], [-0.458, -1.153], [-0.683, -0.680], [-0.670, -0.742], [-0.556, -0.903],
            [-0.283, -1.349], [-0.379, -1.246], [-0.491, -1.102], [-0.598, -0.860], [-0.689, -0.043], [-0.633, -0.815],
            [-0.417, -1.203], [-0.693, -0.025], [-0.363, -1.262], [-0.377, -1.247], [-0.549, -0.910], [-0.303, -1.326],
            [-0.643, -0.801], [-0.507, -1.070], [-0.564, -0.891], [-0.233, -1.393], [-0.691, -0.034], [-0.420, -1.197],
            [-0.515, -1.051], [-0.677, -0.724], [-0.583, -0.876], [-0.307, -1.324], [-0.388, -1.238], [-0.466, -1.142],
            [-0.621, -0.833], [-0.445, -1.170], [-0.667, -0.754], [-0.117, -1.412], [-0.343, -1.285], [-0.573, -0.883],
            [-0.404, -1.212], [-0.658, -0.775], [-0.292, -1.340], [-0.526, -1.000], [-0.433, -1.184], [-0.367, -1.260],
            [-0.652, -0.784], [-0.479, -1.123], [-0.522, -1.023], [-0.251, -1.380],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2 = x
            return -(
                .5 * numpy.exp(-10 * ((x1 + .8) ** 2 + .3 * (x2 + .6) ** 2)) +
                .5 * numpy.exp(-9 * (.4 * (x1 + .7) ** 2 + .4 * (x2 - .4) ** 2)) +
                .5 * numpy.exp(-11 * (.2 * (x1 - .6) ** 2 + .5 * (x2 + .5) ** 2)) +
                .5 * numpy.exp(-11 * (.6 * (x1) ** 2 + .5 * (x2 + .8) ** 2)) +
                .5 * numpy.exp(-12 * (.4 * (x1 - .1) ** 2 + .7 * (x2 - .8) ** 2)) +
                .5 * numpy.exp(-13 * (.8 * (x1) ** 2 + .7 * (x2) ** 2)) +
                .5 * numpy.exp(-8 * (.3 * (x1 - .8) ** 2 + .6 * (x2 - .3) ** 2))
            )
        else:
            return -numpy.linalg.norm(x - self.min_loc[0])


class MCMcCourt05(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(MCMcCourt05, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[0.02080787, -0.01383469], [-1, 1]])
        self.fmin = numpy.array([-0.694918380503, -0.837336627122])
        self.fmax = numpy.array([-0.0505587904118, 0])
        self.frontier = numpy.array([
            [-0.352, -0.675], [-0.621, -0.175], [-0.226, -0.750], [-0.678, -0.068], [-0.360, -0.673], [-0.661, -0.108],
            [-0.555, -0.548], [-0.616, -0.186], [-0.394, -0.652], [-0.527, -0.570], [-0.135, -0.803], [-0.238, -0.744],
            [-0.437, -0.622], [-0.639, -0.149], [-0.469, -0.597], [-0.583, -0.242], [-0.171, -0.784], [-0.308, -0.703],
            [-0.512, -0.579], [-0.456, -0.610], [-0.660, -0.110], [-0.346, -0.680], [-0.627, -0.166], [-0.583, -0.506],
            [-0.666, -0.087], [-0.361, -0.671], [-0.532, -0.564], [-0.567, -0.533], [-0.604, -0.205], [-0.375, -0.662],
            [-0.550, -0.553], [-0.143, -0.800], [-0.398, -0.649], [-0.638, -0.149], [-0.567, -0.539], [-0.691, -0.028],
            [-0.304, -0.706], [-0.598, -0.214], [-0.427, -0.629], [-0.671, -0.083], [-0.620, -0.179], [-0.474, -0.596],
            [-0.204, -0.764], [-0.689, -0.043], [-0.339, -0.685], [-0.652, -0.126], [-0.353, -0.675], [-0.604, -0.202],
            [-0.677, -0.068], [-0.367, -0.669], [-0.499, -0.585], [-0.115, -0.820], [-0.681, -0.061], [-0.262, -0.730],
            [-0.429, -0.629], [-0.640, -0.147], [-0.571, -0.532], [-0.164, -0.787], [-0.541, -0.559], [-0.434, -0.626],
            [-0.671, -0.081], [-0.336, -0.687], [-0.651, -0.126], [-0.504, -0.579], [-0.604, -0.204], [-0.420, -0.635],
            [-0.535, -0.563], [-0.130, -0.811], [-0.467, -0.600], [-0.635, -0.156], [-0.289, -0.711], [-0.581, -0.517],
            [-0.695, -0.006], [-0.405, -0.643], [-0.486, -0.591], [-0.683, -0.055], [-0.472, -0.596], [-0.665, -0.093],
            [-0.197, -0.766], [-0.672, -0.079], [-0.374, -0.664], [-0.663, -0.102], [-0.573, -0.527], [-0.615, -0.186],
            [-0.541, -0.561], [-0.246, -0.740], [-0.415, -0.639], [-0.628, -0.161], [-0.693, -0.025], [-0.324, -0.694],
            [-0.591, -0.227], [-0.442, -0.617], [-0.520, -0.573], [-0.461, -0.606], [-0.662, -0.106], [-0.638, -0.151],
            [-0.489, -0.590], [-0.685, -0.051], [-0.333, -0.689], [-0.646, -0.137], [-0.545, -0.554], [-0.379, -0.659],
            [-0.692, -0.027], [-0.596, -0.215], [-0.252, -0.730], [-0.395, -0.651], [-0.118, -0.820], [-0.288, -0.713],
            [-0.409, -0.641], [-0.572, -0.532], [-0.691, -0.032], [-0.281, -0.719], [-0.596, -0.218], [-0.599, -0.209],
            [-0.454, -0.610], [-0.217, -0.756], [-0.683, -0.059], [-0.351, -0.678], [-0.655, -0.120], [-0.564, -0.541],
            [-0.610, -0.195], [-0.385, -0.657], [-0.518, -0.575], [-0.240, -0.741], [-0.452, -0.611], [-0.643, -0.141],
            [-0.464, -0.601], [-0.624, -0.172], [-0.582, -0.511], [-0.189, -0.771], [-0.690, -0.034], [-0.330, -0.690],
            [-0.584, -0.240], [-0.448, -0.615], [-0.658, -0.112], [-0.364, -0.669], [-0.625, -0.170], [-0.606, -0.200],
            [-0.391, -0.652], [-0.542, -0.558], [-0.132, -0.811], [-0.404, -0.645], [-0.564, -0.541], [-0.159, -0.789],
            [-0.694, -0.015], [-0.311, -0.702], [-0.594, -0.222], [-0.430, -0.628], [-0.625, -0.171], [-0.207, -0.761],
            [-0.687, -0.045], [-0.346, -0.681], [-0.653, -0.125], [-0.674, -0.073], [-0.375, -0.664], [-0.492, -0.589],
            [-0.656, -0.116], [-0.272, -0.725], [-0.633, -0.156], [-0.576, -0.525], [-0.169, -0.785], [-0.306, -0.704],
            [-0.538, -0.562], [-0.439, -0.622], [-0.669, -0.086], [-0.682, -0.060], [-0.343, -0.683], [-0.644, -0.138],
            [-0.380, -0.658], [-0.602, -0.209], [-0.412, -0.640], [-0.528, -0.569], [-0.263, -0.725], [-0.650, -0.129],
            [-0.480, -0.594], [-0.290, -0.708], [-0.578, -0.523], [-0.693, -0.022], [-0.285, -0.717], [-0.440, -0.619],
            [-0.464, -0.603], [-0.181, -0.778], [-0.582, -0.510], [-0.573, -0.530], [-0.611, -0.194], [-0.357, -0.675],
            [-0.553, -0.552], [-0.149, -0.795], [-0.679, -0.064], [-0.263, -0.729], [-0.430, -0.628], [-0.121, -0.811],
            [-0.565, -0.539], [-0.155, -0.794], [-0.691, -0.030], [-0.331, -0.690], [-0.587, -0.235], [-0.435, -0.622],
            [-0.459, -0.607], [-0.670, -0.086], [-0.632, -0.161], [-0.478, -0.596], [-0.687, -0.044], [-0.324, -0.695],
            [-0.647, -0.136], [-0.388, -0.655], [-0.399, -0.648], [-0.502, -0.583], [-0.112, -0.826], [-0.417, -0.637],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2 = x
            return -(
                .5 * numpy.exp(-10 * ((x1 + .8) ** 2 + .3 * (x2 + .6) ** 2)) +
                .5 * numpy.exp(-9 * (.4 * (x1 + .7) ** 2 + .4 * (x2 - .4) ** 2)) +
                .5 * numpy.exp(-11 * (.2 * (x1 - .6) ** 2 + .5 * (x2 + .5) ** 2)) +
                .5 * numpy.exp(-11 * (.6 * (x1) ** 2 + .5 * (x2 + .8) ** 2)) +
                .5 * numpy.exp(-12 * (.4 * (x1 - .1) ** 2 + .7 * (x2 - .8) ** 2)) +
                .5 * numpy.exp(-13 * (.8 * (x1) ** 2 + .7 * (x2) ** 2)) +
                .5 * numpy.exp(-8 * (.3 * (x1 - .8) ** 2 + .6 * (x2 - .3) ** 2))
            )
        else:
            sol1 = self.min_loc[0]
            sol2 = numpy.array([[0.08827771, -0.6818113]])
            return -1 / (1 / numpy.linalg.norm(x - sol1) + 1 / numpy.linalg.norm(x - sol2))


class MCMcCourt06(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(MCMcCourt06, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[-0.08423801, -0.69410345, 0.84013644], [1, 1, -1]])
        self.fmin = numpy.array([-0.92883058216, -2.72610723917])
        self.fmax = numpy.array([-0.00130384569593, 0])
        self.frontier = numpy.array([
            [-0.722, -2.092], [-0.881, -0.125], [-0.533, -2.433], [-0.429, -2.565], [-0.900, -0.090], [-0.751, -1.959],
            [-0.585, -2.360], [-0.404, -2.603], [-0.869, -1.128], [-0.681, -2.178], [-0.817, -1.234], [-0.887, -0.107],
            [-0.771, -1.555], [-0.915, -0.063], [-0.609, -2.306], [-0.731, -2.059], [-0.576, -2.368], [-0.849, -1.177],
            [-0.529, -2.440], [-0.645, -2.255], [-0.917, -0.053], [-0.894, -0.101], [-0.702, -2.130], [-0.492, -2.491],
            [-0.781, -1.283], [-0.908, -0.077], [-0.764, -1.563], [-0.728, -2.076], [-0.702, -2.134], [-0.642, -2.260],
            [-0.907, -0.079], [-0.367, -2.636], [-0.727, -2.086], [-0.654, -2.233], [-0.842, -1.187], [-0.686, -2.176],
            [-0.518, -2.452], [-0.594, -2.326], [-0.779, -1.522], [-0.745, -2.021], [-0.581, -2.360], [-0.667, -2.212],
            [-0.360, -2.653], [-0.476, -2.500], [-0.912, -0.065], [-0.765, -1.559], [-0.515, -2.454], [-0.887, -0.107],
            [-0.466, -2.526], [-0.819, -1.232], [-0.726, -2.086], [-0.653, -2.236], [-0.895, -0.096], [-0.594, -2.324],
            [-0.522, -2.443], [-0.881, -0.123], [-0.856, -1.155], [-0.450, -2.547], [-0.790, -1.271], [-0.639, -2.261],
            [-0.904, -0.084], [-0.560, -2.394], [-0.690, -2.173], [-0.844, -1.186], [-0.710, -2.112], [-0.440, -2.553],
            [-0.754, -1.950], [-0.499, -2.483], [-0.645, -2.252], [-0.557, -2.395], [-0.699, -2.135], [-0.386, -2.622],
            [-0.780, -1.514], [-0.876, -1.113], [-0.921, -0.042], [-0.325, -2.662], [-0.923, -0.038], [-0.624, -2.292],
            [-0.588, -2.340], [-0.724, -2.090], [-0.679, -2.194], [-0.821, -1.210], [-0.398, -2.605], [-0.898, -0.096],
            [-0.785, -1.280], [-0.718, -2.111], [-0.674, -2.208], [-0.590, -2.334], [-0.451, -2.541], [-0.607, -2.324],
            [-0.885, -0.111], [-0.536, -2.428], [-0.919, -0.052], [-0.874, -1.117], [-0.916, -0.061], [-0.382, -2.628],
            [-0.726, -2.088], [-0.894, -0.103], [-0.576, -2.369], [-0.877, -0.127], [-0.740, -2.038], [-0.528, -2.443],
            [-0.614, -2.303], [-0.755, -1.590], [-0.748, -1.972], [-0.895, -0.098], [-0.906, -0.083], [-0.794, -1.268],
            [-0.706, -2.124], [-0.504, -2.473], [-0.657, -2.221], [-0.778, -1.524], [-0.884, -0.121], [-0.504, -2.458],
            [-0.573, -2.375], [-0.832, -1.208], [-0.593, -2.334], [-0.908, -0.076], [-0.924, -0.036], [-0.909, -0.074],
            [-0.636, -2.271], [-0.761, -1.581], [-0.678, -2.201], [-0.803, -1.246], [-0.565, -2.378], [-0.729, -2.066],
            [-0.803, -1.245], [-0.416, -2.587], [-0.619, -2.301], [-0.899, -0.096], [-0.456, -2.529], [-0.386, -2.622],
            [-0.698, -2.158], [-0.550, -2.409], [-0.745, -2.019], [-0.626, -2.287], [-0.428, -2.569], [-0.692, -2.170],
            [-0.753, -1.956], [-0.901, -0.084], [-0.916, -0.060],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2, x3 = x
            return -(
                .5 * numpy.exp(-10 * ((x1 + .8) ** 2 + .3 * (x2 + .6) ** 2 + .7 * (x3 + .7) ** 2)) +
                .5 * numpy.exp(-9 * (.4 * (x1 + .7) ** 2 + .4 * (x2 - .4) ** 2 + .4 * (x3 - .1) ** 2)) +
                .5 * numpy.exp(-11 * (.2 * (x1 - .6) ** 2 + .5 * (x2 + .5) ** 2 + .6 * (x3 + .2) ** 2)) +
                .5 * numpy.exp(-11 * (.6 * (x1) ** 2 + .5 * (x2 + .8) ** 2 + .3 * (x3 - .8) ** 2)) +
                .5 * numpy.exp(-12 * (.4 * (x1 - .1) ** 2 + .7 * (x2 - .8) ** 2 + .8 * (x3 - .4) ** 2)) +
                .5 * numpy.exp(-13 * (.8 * (x1) ** 2 + .7 * (x2) ** 2 + .5 * (x3) ** 2)) +
                .5 * numpy.exp(-8 * (.3 * (x1 - .8) ** 2 + .6 * (x2 - .9) ** 2 + .3 * (x3 + .6) ** 2)) +
                .5 * numpy.exp(-8 * (.5 * (x1 - .3) ** 2 + .5 * (x2 + .2) ** 2 + .5 * (x3 - .4) ** 2)) +
                .5 * numpy.exp(-8 * (.5 * (x1 + .4) ** 2 + .4 * (x2 - .3) ** 2 + .7 * (x3 + .3) ** 2)) +
                .5 * numpy.exp(-8 * (.8 * (x1 + .2) ** 2 + .5 * (x2 + .6) ** 2 + .7 * (x3 - .9) ** 2)) +
                .5 * numpy.exp(-8 * (.9 * (x1 - .5) ** 2 + .6 * (x2 - .7) ** 2 + .4 * (x3 + .1) ** 2))
            )
        else:
            return -numpy.linalg.norm(x - self.min_loc[0])


class MCMcCourt07(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(MCMcCourt07, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-1] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[-0.08423801, -0.69410345, 0.84013644], [1, 1, -1]])
        self.fmin = numpy.array([-0.92883058216, -1.05739720703])
        self.fmax = numpy.array([-0.0011570253227, 0])
        self.frontier = numpy.array([
            [-0.486, -0.940], [-0.812, -0.172], [-0.712, -0.733], [-0.754, -0.657], [-0.919, -0.048], [-0.581, -0.862],
            [-0.828, -0.156], [-0.629, -0.825], [-0.495, -0.931], [-0.694, -0.761], [-0.815, -0.169], [-0.885, -0.105],
            [-0.556, -0.889], [-0.718, -0.730], [-0.619, -0.827], [-0.918, -0.053], [-0.836, -0.150], [-0.515, -0.920],
            [-0.711, -0.734], [-0.477, -0.944], [-0.780, -0.429], [-0.903, -0.078], [-0.876, -0.115], [-0.844, -0.141],
            [-0.702, -0.747], [-0.473, -0.951], [-0.545, -0.897], [-0.839, -0.149], [-0.734, -0.709], [-0.595, -0.856],
            [-0.903, -0.078], [-0.434, -0.977], [-0.895, -0.093], [-0.498, -0.927], [-0.819, -0.166], [-0.743, -0.675],
            [-0.721, -0.730], [-0.678, -0.780], [-0.777, -0.445], [-0.886, -0.099], [-0.596, -0.853], [-0.645, -0.813],
            [-0.662, -0.788], [-0.577, -0.866], [-0.840, -0.143], [-0.748, -0.672], [-0.915, -0.059], [-0.814, -0.170],
            [-0.672, -0.786], [-0.708, -0.737], [-0.907, -0.073], [-0.565, -0.875], [-0.523, -0.913], [-0.623, -0.826],
            [-0.913, -0.063], [-0.854, -0.137], [-0.531, -0.905], [-0.831, -0.155], [-0.926, -0.027], [-0.907, -0.075],
            [-0.792, -0.197], [-0.816, -0.167], [-0.901, -0.083], [-0.449, -0.967], [-0.610, -0.843], [-0.892, -0.094],
            [-0.826, -0.158], [-0.424, -0.984], [-0.652, -0.806], [-0.731, -0.717], [-0.526, -0.909], [-0.452, -0.959],
            [-0.920, -0.044], [-0.356, -1.019], [-0.564, -0.880], [-0.738, -0.694], [-0.696, -0.754], [-0.673, -0.784],
            [-0.691, -0.762], [-0.898, -0.087], [-0.882, -0.107], [-0.878, -0.111], [-0.588, -0.862], [-0.724, -0.720],
            [-0.488, -0.940], [-0.752, -0.662], [-0.625, -0.825], [-0.856, -0.132], [-0.762, -0.477], [-0.688, -0.772],
            [-0.548, -0.890], [-0.750, -0.667], [-0.328, -1.025], [-0.872, -0.116], [-0.430, -0.978], [-0.734, -0.714],
            [-0.918, -0.049], [-0.541, -0.899], [-0.897, -0.089], [-0.616, -0.834], [-0.371, -1.015], [-0.540, -0.901],
            [-0.863, -0.126], [-0.886, -0.101], [-0.703, -0.743], [-0.661, -0.797], [-0.401, -0.997], [-0.782, -0.413],
            [-0.508, -0.926], [-0.464, -0.954], [-0.766, -0.474], [-0.824, -0.159], [-0.564, -0.875], [-0.681, -0.778],
            [-0.906, -0.077], [-0.657, -0.800], [-0.819, -0.165], [-0.803, -0.179], [-0.695, -0.758], [-0.863, -0.126],
            [-0.497, -0.930], [-0.612, -0.838], [-0.739, -0.692], [-0.910, -0.068], [-0.688, -0.765], [-0.912, -0.067],
            [-0.862, -0.126], [-0.811, -0.176], [-0.489, -0.935], [-0.877, -0.114], [-0.601, -0.850], [-0.372, -1.009],
            [-0.466, -0.952], [-0.921, -0.038], [-0.823, -0.164], [-0.406, -0.989], [-0.736, -0.708], [-0.557, -0.885],
            [-0.439, -0.973], [-0.371, -1.010], [-0.528, -0.908], [-0.764, -0.475], [-0.640, -0.814], [-0.892, -0.096],
            [-0.835, -0.152], [-0.799, -0.180], [-0.869, -0.123], [-0.519, -0.915], [-0.775, -0.457], [-0.916, -0.056],
            [-0.592, -0.859], [-0.806, -0.179],
        ])
        self.classifiers = ['nonconvex', 'multisol']

    def do_component_function(self, d, x):
        if d == 0:
            x1, x2, x3 = x
            return -(
                .5 * numpy.exp(-10 * ((x1 + .8) ** 2 + .3 * (x2 + .6) ** 2 + .7 * (x3 + .7) ** 2)) +
                .5 * numpy.exp(-9 * (.4 * (x1 + .7) ** 2 + .4 * (x2 - .4) ** 2 + .4 * (x3 - .1) ** 2)) +
                .5 * numpy.exp(-11 * (.2 * (x1 - .6) ** 2 + .5 * (x2 + .5) ** 2 + .6 * (x3 + .2) ** 2)) +
                .5 * numpy.exp(-11 * (.6 * (x1) ** 2 + .5 * (x2 + .8) ** 2 + .3 * (x3 - .8) ** 2)) +
                .5 * numpy.exp(-12 * (.4 * (x1 - .1) ** 2 + .7 * (x2 - .8) ** 2 + .8 * (x3 - .4) ** 2)) +
                .5 * numpy.exp(-13 * (.8 * (x1) ** 2 + .7 * (x2) ** 2 + .5 * (x3) ** 2)) +
                .5 * numpy.exp(-8 * (.3 * (x1 - .8) ** 2 + .6 * (x2 - .9) ** 2 + .3 * (x3 + .6) ** 2)) +
                .5 * numpy.exp(-8 * (.5 * (x1 - .3) ** 2 + .5 * (x2 + .2) ** 2 + .5 * (x3 - .4) ** 2)) +
                .5 * numpy.exp(-8 * (.5 * (x1 + .4) ** 2 + .4 * (x2 - .3) ** 2 + .7 * (x3 + .3) ** 2)) +
                .5 * numpy.exp(-8 * (.8 * (x1 + .2) ** 2 + .5 * (x2 + .6) ** 2 + .7 * (x3 - .9) ** 2)) +
                .5 * numpy.exp(-8 * (.9 * (x1 - .5) ** 2 + .6 * (x2 - .7) ** 2 + .4 * (x3 + .1) ** 2))
            )
        else:
            sol1 = self.min_loc[0]
            sol2 = numpy.array([[-0.02179115, 0.01597782, -0.01427473]])
            return -1 / (1 / numpy.linalg.norm(x - sol1) + 1 / numpy.linalg.norm(x - sol2))


class MCMcCourt08(MulticriteriaTestFunction):
    def __init__(self, dim=12, verify=True):
        assert dim == 12
        super(MCMcCourt08, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = (
            [700, 1277], [200, 1277], [30, 175], [50, 140], [18, 80], [5, 58],
            [51, 140], [30, 60], [0, 58], [175, 210], [0, 12], [5, 35],
        )
        self.frontier = numpy.array([
            [-0.973, -1.559], [-0.928, -1.601], [-0.951, -1.591], [-0.892, -1.612], [-0.935, -1.598],
            [-1.496, -0.785], [-0.840, -1.613], [-0.947, -1.593], [-0.921, -1.603], [-0.965, -1.577],
            [-0.933, -1.600], [-0.900, -1.609], [-0.954, -1.588], [-0.898, -1.610], [-0.941, -1.596],
            [-0.972, -1.564], [-0.940, -1.597], [-0.949, -1.592], [-0.967, -1.574], [-0.961, -1.581],
            [-0.904, -1.609], [-1.502, -0.779], [-1.503, -0.777], [-1.507, -0.769], [-0.931, -1.600],
            [-0.895, -1.611], [-0.970, -1.570], [-0.903, -1.609], [-1.496, -0.787], [-1.502, -0.777],
            [-0.912, -1.606], [-1.499, -0.784], [-1.501, -0.781], [-1.505, -0.774], [-1.505, -0.772],
            [-1.507, -0.770], [-1.508, -0.761], [-1.510, -0.749], [-1.513, -0.735], [-1.514, -0.730],
            [-1.515, -0.727], [-1.513, -0.737], [-0.815, -1.615], [-0.815, -1.615], [-0.820, -1.615],
            [-0.816, -1.615], [-0.829, -1.614], [-0.814, -1.615], [-1.435, -0.810], [-0.996, -1.499],
            [-1.385, -0.819], [-1.002, -1.480], [-1.009, -1.437], [-1.375, -0.826], [-1.006, -1.452],
            [-1.320, -0.833], [-1.326, -0.833], [-1.014, -1.401], [-1.016, -1.364], [-1.332, -0.832],
            [-1.018, -1.329], [-1.281, -0.841], [-1.020, -1.305], [-1.022, -1.265], [-1.021, -1.297],
            [-1.255, -0.846], [-1.256, -0.845], [-1.160, -0.858], [-1.222, -0.850], [-1.183, -0.853],
            [-1.179, -0.854], [-1.174, -0.855], [-1.024, -1.211], [-1.101, -0.865], [-1.091, -0.866],
            [-1.091, -0.866], [-1.095, -0.865], [-1.025, -1.204], [-1.028, -1.131], [-1.056, -0.870],
            [-1.028, -1.098], [-1.029, -1.065], [-1.029, -1.027], [-1.031, -0.893], [-1.030, -0.990],
            [-1.030, -0.970], [-0.916, -1.604], [-1.031, -0.923], [-0.896, -1.610], [-0.886, -1.612],
            [-0.886, -1.612], [-0.832, -1.614], [-1.081, -0.867], [-1.030, -1.015], [-1.030, -1.001],
            [-1.240, -0.848], [-1.018, -1.360], [-1.023, -1.255], [-1.125, -0.861], [-1.031, -0.941],
            [-1.030, -0.961], [-1.024, -1.250], [-1.026, -1.191], [-1.021, -1.296], [-0.977, -1.530],
            [-1.444, -0.797], [-1.467, -0.795], [-0.980, -1.501], [-1.420, -0.819], [-1.445, -0.795],
        ])
        self.classifiers = ['nonconvex', 'rescaled']

    def do_component_function(self, d, x):
        sx = numpy.empty(self.dim)
        for k, b in enumerate(self.bounds):
            b_min, b_max = b
            sx[k] = (x[k] - b_min) / (b_max - b_min)
        nonconvex_factor = 3
        if d == 0:
            scaling1 = numpy.linspace(1 / self.dim, 1.0, self.dim)
            scaling2 = numpy.linspace(1.3, 1 / self.dim, self.dim)
            distance1_sq = numpy.dot(sx - 1 / 3, scaling1 * (sx - 1 / 3))
            distance2_sq = numpy.dot(sx - 2 / 3, scaling2 * (sx - 2 / 3))
            return (
                -numpy.exp(-2 * distance1_sq * nonconvex_factor) -
                1.5 * numpy.exp(-1.6 * distance2_sq * nonconvex_factor)
            )
        else:
            scaling1 = numpy.linspace(1.3, 1 / self.dim, self.dim)
            scaling2 = numpy.linspace(1 / self.dim, 1.0, self.dim)
            distance1_sq = numpy.dot(sx - 0.25, scaling1 * (sx - 0.25))
            distance2_sq = numpy.dot(sx - 0.6, scaling2 * (sx - 0.6))
            return (
                -1.6 * numpy.exp(-1.2 * distance1_sq * nonconvex_factor) -
                .8 * numpy.exp(-1.7 * distance2_sq * nonconvex_factor)
            )


class FonsecaFleming(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(FonsecaFleming, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-4] * self.dim, [4] * self.dim)
        self.min_loc = numpy.array([[-1.66660505, 3.08081861], [-1.39795592, -0.01625764]])
        self.fmin = numpy.array([0, 0])
        self.fmax = numpy.array([1, 1])
        self.frontier = numpy.array([
            [0.972, 0.011], [0.702, 0.582], [0.195, 0.905], [0.007, 0.975], [0.917, 0.163], [0.536, 0.720],
            [0.794, 0.428], [0.169, 0.919], [0.391, 0.814], [0.951, 0.068], [0.680, 0.586], [0.853, 0.317],
            [0.038, 0.961], [0.115, 0.935], [0.000, 0.982], [0.952, 0.066], [0.468, 0.774], [0.782, 0.448],
            [0.967, 0.033], [0.284, 0.867], [0.548, 0.710], [0.114, 0.936], [0.580, 0.687], [0.847, 0.352],
            [0.923, 0.149], [0.646, 0.619], [0.834, 0.361], [0.722, 0.532], [0.218, 0.897], [0.899, 0.210],
            [0.428, 0.794], [0.041, 0.961], [0.963, 0.033], [0.692, 0.582], [0.489, 0.768], [0.142, 0.925],
            [0.915, 0.173], [0.524, 0.727], [0.820, 0.382], [0.969, 0.022], [0.803, 0.420], [0.389, 0.817],
            [0.957, 0.057], [0.635, 0.631], [0.878, 0.261], [0.018, 0.969], [0.136, 0.929], [0.003, 0.977],
            [0.512, 0.742], [0.740, 0.507], [0.734, 0.528], [0.226, 0.893], [0.921, 0.155], [0.030, 0.965],
            [0.854, 0.317], [0.342, 0.842], [0.948, 0.078], [0.593, 0.672], [0.830, 0.362], [0.717, 0.536],
            [0.876, 0.269], [0.502, 0.743], [0.081, 0.946], [0.271, 0.883], [0.714, 0.545], [0.980, 0.001],
            [0.963, 0.034], [0.899, 0.236], [0.141, 0.925], [0.017, 0.970], [0.915, 0.169], [0.577, 0.687],
            [0.787, 0.436], [0.403, 0.808], [0.710, 0.578], [0.944, 0.091], [0.673, 0.590], [0.849, 0.323],
            [0.686, 0.583], [0.093, 0.943], [0.950, 0.075], [0.454, 0.780], [0.763, 0.489], [0.768, 0.466],
            [0.330, 0.846], [0.886, 0.254], [0.284, 0.871], [0.973, 0.010], [0.252, 0.883], [0.934, 0.119],
            [0.590, 0.672], [0.830, 0.376], [0.077, 0.952], [0.672, 0.590], [0.206, 0.901], [0.906, 0.195],
            [0.446, 0.783], [0.050, 0.958], [0.758, 0.506], [0.963, 0.039], [0.323, 0.855], [0.158, 0.922],
            [0.007, 0.977], [0.930, 0.135], [0.818, 0.382], [0.975, 0.008], [0.816, 0.414], [0.447, 0.781],
            [0.166, 0.921], [0.955, 0.058], [0.626, 0.639], [0.874, 0.281], [0.043, 0.959], [0.870, 0.288],
            [0.130, 0.930], [0.938, 0.115], [0.493, 0.765], [0.769, 0.465], [0.766, 0.478], [0.272, 0.873],
            [0.494, 0.757], [0.914, 0.188], [0.944, 0.098], [0.378, 0.822], [0.934, 0.115],
        ])
        self.classifiers = ['unimodal', 'nonconvex']

    def do_component_function(self, d, x):
        if d == 0:
            return 1 - numpy.exp(-sum((x - 1.0 / numpy.sqrt(self.dim)) ** 2))
        else:
            return 1 - numpy.exp(-sum((x + 1.0 / numpy.sqrt(self.dim)) ** 2))


class Kursawe(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(Kursawe, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-5] * self.dim, [5] * self.dim)
        self.min_loc = numpy.array([[0, 0, 0], [1.6745019, -1.15274094, -1.15274096]])
        self.fmin = numpy.array([-20, -11.2403310376])
        self.fmax = numpy.array([-4.86233468868, 24.8876802177])
        self.frontier = numpy.array([
            [-18.151, -1.501], [-16.565, -5.379], [-16.413, -6.191], [-15.980, -7.470], [-19.909, 0.111],
            [-18.581, -1.075], [-16.413, -6.131], [-16.554, -5.439], [-16.837, -4.169], [-15.523, -8.091],
            [-16.231, -6.935], [-15.082, -9.832], [-14.515, -11.584], [-17.028, -3.827], [-14.688, -11.236],
            [-15.385, -8.369], [-16.326, -6.586], [-16.335, -6.423], [-16.172, -7.086], [-16.635, -5.153],
            [-18.592, -0.343], [-16.798, -4.244], [-16.611, -5.282], [-17.991, -3.344], [-18.476, -1.157],
            [-16.778, -4.353], [-15.973, -7.504], [-14.793, -10.818], [-18.073, -3.202], [-15.339, -8.732],
            [-16.307, -6.656], [-18.591, -0.371], [-16.679, -4.908], [-18.111, -3.111], [-14.816, -10.762],
            [-17.898, -3.810], [-16.151, -7.167], [-16.378, -6.392], [-14.491, -11.607], [-16.706, -4.759],
            [-14.951, -10.208], [-16.232, -6.748], [-18.766, 0.090], [-14.728, -10.879], [-14.879, -10.586],
            [-16.452, -5.980], [-16.382, -6.352], [-18.365, -1.261], [-15.916, -7.523], [-16.909, -3.972],
            [-15.624, -7.684], [-16.715, -4.646], [-16.383, -6.248], [-15.026, -9.921], [-15.849, -7.554],
            [-15.678, -7.608], [-15.923, -7.519], [-16.728, -4.482], [-15.975, -7.476], [-16.254, -6.693],
            [-15.998, -7.447], [-16.076, -7.316], [-15.151, -9.209], [-16.513, -5.736], [-15.145, -9.452],
            [-17.929, -3.791], [-18.693, -0.007], [-16.724, -4.593], [-14.862, -10.637], [-15.853, -7.532],
            [-16.909, -3.972], [-15.625, -7.683], [-18.203, -1.439], [-14.948, -10.358], [-16.895, -4.012],
            [-15.605, -7.765], [-18.142, -2.987], [-16.955, -3.955], [-18.145, -2.962], [-15.593, -7.844],
            [-14.725, -11.124], [-16.195, -7.019],
        ])
        self.classifiers = ['nonconvex']

    def do_component_function(self, d, x):
        if d == 0:
            return sum(-10 * numpy.exp(-.2 * numpy.sqrt(x[:-1] ** 2 + x[1:] ** 2)))
        else:
            return sum(abs(x) ** .8 + 5 * numpy.sin(x ** 3))


class Schaffer01(MulticriteriaTestFunction):
    def __init__(self, dim=1, verify=True):
        assert dim == 1
        super(Schaffer01, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-100], [100])
        self.min_loc = numpy.array([[0], [2]])
        self.fmin = numpy.array([0, 0])
        self.fmax = numpy.array([10000, 10404])
        self.frontier = numpy.array([
            [0.398, 1.874], [1.995, 0.345], [1.044, 0.957], [0.058, 3.096], [3.251, 0.039], [0.683, 1.377],
            [0.002, 3.821], [2.585, 0.154], [1.481, 0.613], [0.190, 2.447], [3.993, 0.000], [0.531, 1.616],
            [2.280, 0.240], [1.253, 0.776], [0.114, 2.762], [3.612, 0.010], [0.854, 1.158], [0.020, 3.449],
            [2.908, 0.087], [1.728, 0.470], [0.285, 2.151], [0.462, 1.743], [2.135, 0.290], [1.146, 0.864],
            [0.084, 2.927], [3.429, 0.022], [0.766, 1.265], [0.009, 3.633], [2.744, 0.118], [1.602, 0.539],
            [0.235, 2.296], [0.605, 1.494], [0.000, 4.015], [2.430, 0.195], [1.365, 0.692], [0.150, 2.602],
            [3.800, 0.003], [0.946, 1.055], [0.037, 3.270], [3.077, 0.060], [1.859, 0.405], [0.339, 2.010],
            [0.430, 1.808], [2.064, 0.317], [1.094, 0.910], [0.070, 3.011], [3.339, 0.030], [0.724, 1.321],
            [0.005, 3.727], [2.664, 0.135], [1.541, 0.575], [0.212, 2.371], [0.567, 1.555], [2.354, 0.217],
            [1.308, 0.733], [0.131, 2.681], [3.706, 0.006], [0.900, 1.106], [0.028, 3.359], [2.992, 0.073],
            [1.793, 0.437], [0.311, 2.080], [0.496, 1.679], [2.207, 0.265], [1.199, 0.819], [0.098, 2.844],
            [3.520, 0.015], [0.809, 1.211], [0.014, 3.540], [2.825, 0.102], [1.665, 0.504], [0.259, 2.223],
            [0.643, 1.435], [0.000, 3.918], [2.507, 0.174], [1.422, 0.652], [0.169, 2.524], [3.896, 0.001],
            [0.995, 1.005], [0.047, 3.182], [3.163, 0.049], [1.926, 0.375], [0.368, 1.941], [0.414, 1.841],
            [2.029, 0.331], [1.069, 0.933], [0.064, 3.053], [3.295, 0.034], [0.703, 1.349], [0.003, 3.774],
            [2.624, 0.145], [1.511, 0.594], [0.201, 2.409], [0.549, 1.585], [2.317, 0.228], [1.280, 0.754],
            [0.123, 2.721], [3.659, 0.008], [0.877, 1.132], [0.024, 3.404], [2.950, 0.080],
        ])
        self.classifiers = ['unimodal', 'unscaled']

    def do_component_function(self, d, x):
        x1 = x[0]
        if d == 0:
            return x1 ** 2
        else:
            return (x1 - 2) ** 2


class Schaffer02(MulticriteriaTestFunction):
    def __init__(self, dim=1, verify=True):
        assert dim == 1
        super(Schaffer02, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-5], [10])
        self.min_loc = numpy.array([[1], [5]])
        self.fmin = numpy.array([1, 0])
        self.fmax = numpy.array([6, 100])
        self.frontier = numpy.array([
            [0.294, 0.499], [-0.519, 12.382], [-0.988, 15.900], [0.762, 0.056], [-0.050, 9.303], [0.528, 0.223],
            [-0.284, 10.787], [-0.753, 14.086], [0.997, 0.000], [0.059, 0.885], [0.411, 0.347], [-0.402, 11.571],
            [-0.870, 14.980], [0.880, 0.014], [0.645, 0.126], [-0.167, 10.031], [-0.636, 13.220], [0.177, 0.678],
            [0.352, 0.420], [-0.460, 11.973], [-0.929, 15.437], [0.821, 0.032], [0.587, 0.171], [-0.226, 10.406],
            [-0.695, 13.650], [0.118, 0.778], [0.469, 0.281], [-0.343, 11.176], [-0.812, 14.529], [0.938, 0.004],
            [0.001, 0.999], [0.704, 0.088], [-0.109, 9.664], [-0.577, 12.798], [0.235, 0.585], [0.323, 0.458],
            [-0.489, 12.177], [-0.958, 15.668], [0.792, 0.043], [-0.021, 9.125], [0.557, 0.196], [-0.255, 10.596],
            [-0.724, 13.867], [0.089, 0.831], [0.440, 0.313], [-0.372, 11.372], [-0.841, 14.754], [0.909, 0.008],
            [0.675, 0.106], [-0.138, 9.847], [-0.607, 13.008], [0.206, 0.631], [0.382, 0.382], [-0.431, 11.771],
            [-0.900, 15.207], [0.850, 0.022], [0.616, 0.147], [-0.197, 10.218], [-0.665, 13.434], [0.147, 0.727],
            [0.499, 0.251], [-0.314, 10.981], [-0.782, 14.307], [0.968, 0.001], [0.030, 0.941], [0.733, 0.071],
            [-0.079, 9.482], [-0.548, 12.589], [0.264, 0.541], [0.308, 0.478], [-0.504, 12.279], [-0.973, 15.784],
            [0.777, 0.050], [-0.035, 9.214], [0.543, 0.209], [-0.270, 10.691], [-0.739, 13.976], [0.074, 0.858],
            [0.426, 0.330], [-0.387, 11.471], [-0.856, 14.866], [0.894, 0.011], [0.660, 0.116], [-0.153, 9.939],
            [-0.621, 13.114], [0.191, 0.654], [0.367, 0.401], [-0.446, 11.872], [-0.914, 15.322], [0.836, 0.027],
            [0.601, 0.159], [-0.211, 10.312], [-0.680, 13.542], [0.133, 0.752], [0.484, 0.266], [-0.328, 11.078],
            [-0.797, 14.418], [0.953, 0.002], [0.015, 0.969], [0.719, 0.079], [-0.094, 9.573], [-0.563, 12.693],
            [0.250, 0.563], [0.338, 0.439], [-0.475, 12.075], [-0.944, 15.552], [0.806, 0.037], [-0.006, 9.037],
            [0.572, 0.183], [-0.240, 10.501], [-0.709, 13.758], [0.103, 0.804], [0.455, 0.297], [-0.358, 11.274],
            [-0.826, 14.641], [0.924, 0.006], [0.689, 0.097], [-0.123, 9.755], [-0.592, 12.903], [0.220, 0.608],
            [0.396, 0.365], [-0.416, 11.671], [-0.885, 15.093], [0.865, 0.018], [0.631, 0.136], [-0.182, 10.124],
            [-0.651, 13.327], [0.162, 0.702], [0.513, 0.237], [-0.299, 10.884], [-0.768, 14.196], [0.982, 0.000],
            [0.045, 0.913], [-0.998, 16.017], [0.748, 0.064], [-0.065, 9.392], [-0.533, 12.485], [0.279, 0.520],
            [0.301, 0.489], [-0.511, 12.330], [-0.980, 15.842], [0.770, 0.053], [-0.043, 9.258], [0.535, 0.216],
            [-0.277, 10.739], [-0.746, 14.031], [0.067, 0.871], [0.418, 0.338], [-0.394, 11.521], [-0.863, 14.923],
            [0.887, 0.013], [0.653, 0.121], [-0.160, 9.985], [-0.629, 13.167], [0.184, 0.666], [0.360, 0.410],
            [-0.453, 11.922], [-0.922, 15.379], [0.828, 0.029], [0.594, 0.165], [-0.218, 10.359], [-0.687, 13.596],
            [0.125, 0.765], [0.477, 0.274], [-0.336, 11.127], [-0.804, 14.474], [0.946, 0.003], [0.008, 0.984],
            [0.711, 0.083], [-0.101, 9.618], [-0.570, 12.745], [0.242, 0.574], [0.330, 0.448], [-0.482, 12.125],
            [-0.951, 15.610], [0.799, 0.040], [-0.013, 9.081], [0.565, 0.189], [-0.248, 10.548], [-0.717, 13.813],
            [0.096, 0.817], [0.448, 0.305], [-0.365, 11.323], [-0.834, 14.697], [0.916, 0.007], [0.682, 0.101],
            [-0.131, 9.801], [-0.599, 12.955], [0.213, 0.619], [0.389, 0.373], [-0.424, 11.721], [-0.892, 15.150],
            [0.858, 0.020], [0.623, 0.142], [-0.189, 10.171], [-0.658, 13.381], [0.155, 0.715], [0.506, 0.244],
            [-0.306, 10.932], [-0.775, 14.252], [0.975, 0.001], [0.037, 0.927], [0.740, 0.067], [-0.072, 9.437],
            [-0.541, 12.537], [0.272, 0.530], [0.316, 0.468], [-0.497, 12.228], [-0.966, 15.726], [0.784, 0.046],
            [-0.028, 9.169], [0.550, 0.202], [-0.262, 10.644], [-0.731, 13.922], [0.081, 0.844], [0.433, 0.322],
            [-0.380, 11.422], [-0.848, 14.810], [0.902, 0.010], [0.667, 0.111], [-0.145, 9.893], [-0.614, 13.061],
            [0.198, 0.642], [0.374, 0.392], [-0.438, 11.821], [-0.907, 15.264], [0.843, 0.025], [0.609, 0.153],
            [-0.204, 10.265], [-0.673, 13.488], [0.140, 0.740], [0.491, 0.259], [-0.321, 11.029], [-0.790, 14.362],
            [0.960, 0.002], [0.023, 0.955], [0.726, 0.075], [-0.087, 9.527], [-0.555, 12.641], [0.257, 0.552],
            [0.345, 0.429], [-0.468, 12.024], [-0.936, 15.494], [0.814, 0.035], [0.579, 0.177], [-0.233, 10.453],
            [-0.702, 13.704], [0.111, 0.791], [0.462, 0.289], [-0.350, 11.225], [-0.819, 14.585], [0.931, 0.005],
            [0.697, 0.092], [-0.116, 9.709], [-0.585, 12.850], [0.228, 0.596], [0.404, 0.356], [-0.409, 11.621],
            [-0.878, 15.036], [0.872, 0.016], [0.638, 0.131], [-0.175, 10.078], [-0.643, 13.274], [0.169, 0.690],
            [0.521, 0.230], [-0.292, 10.836],
        ])
        self.classifiers = ['nonconvex']

    def do_component_function(self, d, x):
        x1 = x[0]
        if d == 0:
            if x1 <= 1:
                return -x1
            elif x1 <= 3:
                return x1 - 2
            elif x1 <= 4:
                return 4 - x1
            else:
                return x1 - 4
        else:
            return (x1 - 5) ** 2


class Poloni(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(Poloni, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([-numpy.pi] * 2, [numpy.pi] * 2)
        self.min_loc = numpy.array([[1, 2], [-3, -1]])
        self.fmin = numpy.array([1, 0])
        self.fmax = numpy.array([61.6300456149, 54.8719500309])
        self.frontier = numpy.array([
            [10.458, 0.418], [5.243, 1.370], [1.244, 22.767], [16.239, 0.002], [12.448, 0.168], [1.030, 24.099],
            [8.541, 0.686], [1.312, 22.487], [4.174, 1.584], [1.130, 23.345], [1.826, 21.289], [2.365, 2.491],
            [15.541, 0.009], [3.036, 2.077], [1.873, 21.215], [1.091, 23.489], [10.722, 0.358], [1.013, 24.401],
            [7.141, 0.841], [1.555, 21.836], [2.294, 2.610], [1.270, 22.761], [1.403, 22.220], [1.684, 21.578],
            [2.160, 2.921], [14.376, 0.037], [15.320, 0.011], [6.960, 0.889], [1.988, 21.005], [1.182, 22.978],
            [6.127, 1.071], [1.086, 23.533], [1.553, 21.842], [13.652, 0.086], [1.009, 24.490], [12.952, 0.144],
            [3.906, 1.634], [16.822, 0.000], [3.439, 1.876], [1.567, 21.815], [3.207, 1.937], [2.873, 2.139],
            [11.011, 0.307], [1.004, 24.632], [9.357, 0.522], [15.871, 0.005], [2.099, 2.987], [1.278, 22.601],
            [14.930, 0.019], [4.391, 1.553], [1.101, 23.477], [1.672, 21.613], [5.778, 1.114], [1.655, 21.656],
            [1.176, 23.005], [1.033, 24.067], [1.363, 22.339], [13.140, 0.114], [1.232, 22.852], [1.476, 22.033],
            [3.663, 1.744], [1.859, 21.252], [4.721, 1.405], [15.782, 0.007], [2.089, 20.843], [1.158, 23.102],
            [10.019, 0.435], [11.642, 0.267], [1.035, 23.999], [8.063, 0.697], [1.707, 21.521], [7.547, 0.814],
            [1.189, 22.958], [2.272, 2.675], [14.784, 0.022], [1.727, 21.478], [1.001, 25.116], [1.134, 23.321],
            [5.941, 1.089], [1.125, 23.399], [12.247, 0.221], [2.215, 2.904], [1.175, 23.027], [1.353, 22.365],
            [2.859, 2.178], [2.020, 20.977], [12.644, 0.154], [1.420, 22.197], [6.386, 1.063], [2.003, 20.988],
            [5.673, 1.166], [1.912, 21.146], [8.572, 0.648], [1.304, 22.535], [1.173, 23.041], [14.656, 0.025],
            [16.505, 0.001], [1.028, 24.118], [1.421, 22.168], [9.568, 0.476], [3.047, 2.008], [1.538, 21.915],
            [2.362, 2.556], [15.303, 0.013], [1.078, 23.579], [4.208, 1.574], [1.370, 22.333], [1.028, 24.222],
            [9.071, 0.555], [1.245, 22.763], [7.926, 0.735], [15.466, 0.009], [1.055, 23.818], [1.957, 21.059],
            [5.278, 1.233], [4.565, 1.541], [3.384, 1.908], [14.333, 0.044], [1.196, 22.919], [16.097, 0.002],
            [4.616, 1.423], [1.714, 21.500], [6.535, 1.000], [2.431, 2.410], [11.344, 0.279], [1.149, 23.138],
            [2.057, 20.910], [1.354, 22.356], [4.994, 1.394], [2.603, 2.333], [1.342, 22.399], [2.219, 2.700],
            [15.959, 0.005], [1.056, 23.773], [2.025, 20.945], [11.957, 0.258], [1.872, 21.230], [8.679, 0.619],
            [1.002, 24.755], [13.906, 0.060], [6.643, 0.942], [1.478, 22.021], [13.438, 0.098], [1.071, 23.646],
            [3.778, 1.701], [2.667, 2.217], [15.147, 0.016], [11.312, 0.296], [1.057, 23.765], [1.716, 21.494],
            [1.604, 21.747], [3.500, 1.803], [1.395, 22.282], [1.290, 22.559], [2.127, 2.960], [15.812, 0.006],
        ])
        self.classifiers = ['unimodal', 'nonconvex']

    def do_component_function(self, d, x):
        x, y = x[0], x[1]
        if d == 0:
            A1 = .5 * numpy.sin(1) - 2 * numpy.cos(1) + numpy.sin(2) - 1.5 * numpy.cos(2)
            A2 = 1.5 * numpy.sin(1) - numpy.cos(1) + 2 * numpy.sin(2) - .5 * numpy.cos(2)
            B1 = .5 * numpy.sin(x) - 2 * numpy.cos(x) + numpy.sin(y) - 1.5 * numpy.cos(y)
            B2 = 1.5 * numpy.sin(x) - numpy.cos(x) + 2 * numpy.sin(y) - .5 * numpy.cos(y)
            return 1 + (A1 - B1) ** 2 + (A2 - B2) ** 2
        else:
            return (x + 3) ** 2 + (y + 1) ** 2


class ZitzlerDebThiele01(MulticriteriaTestFunction):
    def __init__(self, dim=4, verify=True):
        assert dim == 4
        super(ZitzlerDebThiele01, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([
            [0, 0.49819096, 0.95097693, 0.01364007],
            [1, 0, 0, 0],
        ])
        self.fmin = numpy.array([0, 0])
        self.fmax = numpy.array([1, 1.93103448276])
        self.frontier = numpy.array([
            [0.779, 0.139], [0.896, 0.070], [0.348, 0.418], [0.117, 0.697], [0.104, 0.708], [0.043, 0.826],
            [0.473, 0.324], [0.680, 0.193], [0.129, 0.659], [0.154, 0.641], [0.526, 0.283], [0.000, 1.409],
            [0.603, 0.241], [0.447, 0.347], [0.929, 0.049], [0.313, 0.468], [0.462, 0.341], [0.044, 0.826],
            [0.026, 0.885], [0.224, 0.538], [0.909, 0.060], [0.024, 0.896], [0.366, 0.417], [0.018, 0.905],
            [0.006, 0.967], [0.787, 0.127], [0.559, 0.263], [0.717, 0.175], [0.888, 0.075], [0.135, 0.656],
            [0.677, 0.199], [0.219, 0.571], [0.066, 0.782], [0.337, 0.460], [0.531, 0.281], [0.457, 0.343],
            [0.977, 0.022], [0.667, 0.211], [0.167, 0.623], [0.568, 0.259], [0.052, 0.803], [0.795, 0.116],
            [0.081, 0.743], [0.312, 0.475], [0.031, 0.850], [0.106, 0.704], [0.622, 0.217], [0.103, 0.709],
            [0.011, 0.943], [0.783, 0.128], [0.000, 1.059], [0.987, 0.022], [0.723, 0.161], [0.747, 0.149],
            [0.000, 1.232], [0.868, 0.076], [0.817, 0.113], [0.316, 0.465], [0.088, 0.728], [0.646, 0.212],
            [0.743, 0.156], [0.023, 0.903], [0.297, 0.483], [0.032, 0.836], [0.379, 0.411], [0.150, 0.647],
            [0.101, 0.726], [0.446, 0.349], [0.169, 0.605], [0.600, 0.251], [0.948, 0.045], [0.921, 0.056],
            [0.306, 0.478], [0.190, 0.582], [0.114, 0.699], [0.524, 0.295], [0.117, 0.676], [0.645, 0.214],
            [0.000, 1.230], [0.670, 0.202], [0.416, 0.371], [0.378, 0.413], [0.681, 0.181], [0.904, 0.066],
            [0.154, 0.637], [0.848, 0.095], [0.140, 0.651], [0.000, 1.450], [0.532, 0.279], [0.010, 0.955],
            [0.587, 0.252], [0.479, 0.316], [0.858, 0.089], [0.407, 0.384], [0.068, 0.763], [0.086, 0.735],
            [0.762, 0.142], [0.847, 0.101], [0.512, 0.300], [0.229, 0.536], [0.760, 0.148], [0.382, 0.388],
            [0.052, 0.825], [0.961, 0.037], [0.679, 0.199], [0.828, 0.109], [0.054, 0.793], [0.246, 0.518],
            [0.182, 0.600], [0.002, 0.969], [0.275, 0.491], [0.602, 0.249], [0.031, 0.883], [0.223, 0.559],
            [0.419, 0.368], [0.263, 0.506], [0.425, 0.360], [0.009, 0.956], [0.602, 0.245], [0.199, 0.573],
            [0.326, 0.461], [0.339, 0.430], [0.041, 0.827], [0.014, 0.930], [0.288, 0.483], [0.770, 0.141],
            [0.824, 0.110], [0.000, 1.000],
        ])

    def do_component_function(self, d, x):
        if d == 0:
            return x[0]
        else:
            g = 1 + 9.0 / 29 * sum(x[1:])
            return g * (1 - numpy.sqrt(x[0] / g))


class ZitzlerDebThiele02(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(ZitzlerDebThiele02, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([
            [0., 0.50041072, 0.18539947],
            [1, 0, 0],
        ])
        self.fmin = numpy.array([0, 0])
        self.fmax = numpy.array([1, 1.62068965517])
        self.frontier = numpy.array([
            [0.991, 0.065], [0.271, 0.936], [0.604, 0.657], [0.374, 0.875], [0.842, 0.316], [0.974, 0.078],
            [0.908, 0.223], [0.796, 0.376], [0.868, 0.258], [0.556, 0.709], [0.719, 0.528], [0.917, 0.201],
            [0.377, 0.873], [0.696, 0.528], [0.746, 0.466], [0.476, 0.788], [0.266, 0.942], [0.827, 0.340],
            [0.923, 0.161], [0.068, 0.996], [0.397, 0.862], [0.330, 0.905], [0.680, 0.574], [0.732, 0.470],
            [0.151, 0.983], [0.562, 0.693], [0.751, 0.461], [0.855, 0.286], [0.656, 0.581], [0.719, 0.498],
            [0.247, 0.952], [0.830, 0.339], [0.507, 0.763], [0.946, 0.113], [0.629, 0.610], [0.675, 0.577],
            [0.274, 0.934], [0.450, 0.805], [0.867, 0.264], [0.598, 0.678], [0.878, 0.251], [0.523, 0.738],
            [0.685, 0.545], [0.587, 0.685], [0.323, 0.915], [0.766, 0.419], [0.423, 0.833], [0.993, 0.064],
            [0.234, 0.952], [0.815, 0.367], [0.897, 0.230], [0.970, 0.086], [0.355, 0.895], [0.904, 0.229],
            [0.641, 0.596], [0.371, 0.890], [0.761, 0.456], [0.437, 0.819], [0.133, 0.991], [0.795, 0.403],
            [0.822, 0.351], [0.671, 0.580], [0.966, 0.106], [0.830, 0.329], [0.352, 0.899], [0.000, 1.066],
            [0.401, 0.854], [0.917, 0.183], [0.196, 0.962], [0.541, 0.713], [0.306, 0.920], [0.587, 0.678],
            [0.332, 0.904], [0.779, 0.409], [0.911, 0.207], [0.496, 0.772], [0.944, 0.151], [0.233, 0.958],
            [0.878, 0.241], [0.425, 0.832], [0.479, 0.775], [0.519, 0.744], [0.881, 0.240], [0.995, 0.042],
            [0.731, 0.494], [0.609, 0.642], [0.380, 0.864], [0.514, 0.759], [0.000, 1.000],

        ])
        self.classifiers = ['nonconvex']

    def do_component_function(self, d, x):
        if d == 0:
            return x[0]
        else:
            g = 1 + 9.0 / 29 * sum(x[1:])
            return g * (1 - (x[0] / g) ** 2)


class ZitzlerDebThiele03(MulticriteriaTestFunction):
    def __init__(self, dim=4, verify=True):
        assert dim == 4
        super(ZitzlerDebThiele03, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([
            [0, 0.86803868, 0.71117013, 0.64351864],
            [0.85183286, 0, 0, 0]
        ])
        self.fmin = numpy.array([0, -0.773369012327])
        self.fmax = numpy.array([1, 1.93103448276])
        self.frontier = numpy.array([
            [0.424, 0.105], [0.831, -0.543], [0.000, 1.292], [0.839, -0.632], [0.621, -0.105], [0.000, 1.606],
            [0.642, -0.347], [0.001, 1.107], [0.628, -0.252], [0.057, 0.780], [0.846, -0.711], [0.647, -0.403],
            [0.204, 0.563], [0.439, -0.028], [0.023, 0.860], [0.256, 0.288], [0.424, 0.133], [0.840, -0.653],
            [0.240, 0.353], [0.033, 0.812], [0.213, 0.533], [0.445, -0.084], [0.191, 0.690], [0.430, 0.037],
            [0.837, -0.629], [0.014, 0.928], [0.002, 0.957], [0.000, 1.299], [0.222, 0.466], [0.433, 0.025],
            [0.625, -0.172], [0.855, -0.740], [0.416, 0.248], [0.268, 0.277], [0.191, 0.708], [0.419, 0.165],
            [0.842, -0.707], [0.225, 0.410], [0.071, 0.720], [0.045, 0.808], [0.243, 0.345], [0.829, -0.511],
            [0.644, -0.385], [0.850, -0.735], [0.422, 0.137], [0.198, 0.621], [0.001, 1.075], [0.834, -0.586],
            [0.638, -0.345], [0.437, 0.010], [0.215, 0.488], [0.823, -0.422], [0.000, 1.667], [0.252, 0.290],
            [0.831, -0.536], [0.444, -0.057], [0.049, 0.804], [0.833, -0.572], [0.634, -0.306], [0.064, 0.741],
            [0.246, 0.307], [0.202, 0.614], [0.428, 0.039], [0.414, 0.248], [0.233, 0.372], [0.627, -0.181],
            [0.215, 0.499], [0.194, 0.672], [0.438, -0.015], [0.837, -0.611], [0.451, -0.095], [0.000, 1.644],
            [0.417, 0.204], [0.000, 1.214], [0.198, 0.653], [0.628, -0.183], [0.247, 0.303], [0.417, 0.204],
            [0.032, 0.847], [0.631, -0.281], [0.848, -0.712], [0.650, -0.421], [0.058, 0.746], [0.624, -0.111],
            [0.220, 0.477], [0.826, -0.451], [0.000, 1.207], [0.619, -0.102], [0.637, -0.316], [0.223, 0.454],
            [0.000, 1.000],
        ])
        self.classifiers = ['nonconvex']

    def do_component_function(self, d, x):
        if d == 0:
            return x[0]
        else:
            g = 1 + 9.0 / 29 * sum(x[1:])
            return g * (1 - numpy.sqrt(x[0] / g) - (x[0] / g) * numpy.sin(10 * numpy.pi * x[0]))


# Note(Mike) - This is not the version from Wikipedia, it is from
#       http://www.egr.msu.edu/~kdeb/papers/k2006001.pdf
class ZitzlerDebThiele04(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(ZitzlerDebThiele04, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] + [-5] * (self.dim - 1), [1] + [5] * (self.dim - 1))
        self.min_loc = numpy.array([
            [0, -3.42837294, -2.52743626],
            [1, 0, 0],
        ])
        self.fmin = numpy.array([0, 0])
        self.fmax = numpy.array([1, 66.657505914])
        self.frontier = numpy.array([
            [0.041, 1.148], [0.234, 0.520], [0.000, 1.368],
            [0.010, 1.261], [0.897, 0.369], [0.041, 1.031], [0.632, 0.438],
            [0.587, 0.448], [0.177, 1.003], [0.877, 0.419], [0.166, 1.004],
            [0.921, 0.350],
        ])

    def do_component_function(self, d, x):
        D = numpy.array([  # Randomly constructed
            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, -0.66, -0.11, -0.61, -0.19, -0.00, -0.65, 0.99, -0.86, 0.06],
            [0, -0.35, 0.55, -0.79, -0.05, -0.46, 0.15, -0.03, -0.83, -0.22],
            [0, 0.39, -0.70, -0.15, -0.56, -0.17, 0.23, -0.78, -0.06, -0.13],
            [0, -0.86, -0.77, -0.87, -0.14, 0.03, -0.96, 0.91, 0.13, -0.81],
            [0, 0.04, 0.09, 0.55, -0.04, -0.83, 0.12, 0.52, -0.67, -0.40],
            [0, -0.06, -0.94, 0.67, 0.68, 0.61, 0.43, 0.34, -0.08, 0.46],
            [0, 0.33, -0.40, -0.83, -0.64, 0.67, 0.49, 0.08, 0.56, 0.42],
            [0, 0.54, -0.77, -0.25, -0.52, -0.71, -0.36, -0.44, 0.40, -0.98],
            [0, -0.87, -0.00, 0.36, -0.38, 0.84, 0.72, 0.94, 0.42, -0.64],
        ])
        y = numpy.dot(D[:self.dim, :self.dim], x)
        f = y[0] ** 2
        if d == 0:
            return f
        else:
            g = 1 + 10 * (self.dim - 1) + sum(y[1:] ** 2 - 10 * numpy.cos(4 * numpy.pi * y[1:]))
            return g * (1 - numpy.sqrt(f / g))


class ZitzlerDebThiele06(MulticriteriaTestFunction):
    def __init__(self, dim=3, verify=True):
        assert dim == 3
        super(ZitzlerDebThiele06, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([
            [0.08145779, 0.81951852, 0.56948198],
            [1, 0, 0],
        ])
        self.fmin = numpy.array([0.280775318815, 0])
        self.fmax = numpy.array([1, 9.99211652203])
        self.frontier = numpy.array([
            [0.832, 3.091], [0.920, 2.898], [0.980, 2.358], [0.636, 3.259], [0.426, 3.778],
            [0.282, 5.191], [0.874, 3.086], [0.286, 3.919], [0.996, 2.314], [0.284, 4.800],
            [0.281, 5.382], [0.727, 3.101], [0.885, 2.901],
        ])
        self.classifiers = ['nonconvex']

    def do_component_function(self, d, x):
        f1 = 1 - numpy.exp(-4 * x[0]) * numpy.sin(6 * numpy.pi * x[0]) ** 6
        if d == 0:
            return f1
        else:
            g = 1 + 9.0 * (sum(x[1:]) / (self.dim - 1)) ** .25
            return g * (1 - (f1 / g) ** 2)


class CTP01Modified(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(CTP01Modified, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = lzip([0] * self.dim, [1] * self.dim)
        self.min_loc = numpy.array([[6.06354250e-07, 7.33660881e-01], [1, 0.37129138]])
        self.fmin = numpy.array([6.87563675328e-07, 0.695598767821])
        self.fmax = numpy.array([2.97963667915, 2.37650640539])
        self.frontier = numpy.array([
            [0.564, 0.829], [0.379, 0.903], [0.875, 0.734], [0.400, 0.895], [0.778, 0.760], [0.039, 1.071],
            [0.336, 0.922], [0.716, 0.780], [0.154, 1.010], [0.252, 0.961], [0.957, 0.713], [0.365, 0.910],
            [0.743, 0.770], [0.183, 0.995], [0.610, 0.813], [0.920, 0.722], [0.294, 0.941], [0.530, 0.843],
            [0.818, 0.750], [0.342, 0.920], [0.721, 0.777], [0.160, 1.006], [0.954, 0.714], [0.093, 1.041],
            [0.019, 1.097], [0.123, 1.026], [0.504, 0.853], [0.211, 0.983], [1.022, 0.698], [0.429, 0.882],
            [0.808, 0.753], [0.524, 0.846], [0.861, 0.737], [0.063, 1.059], [0.468, 0.867], [0.001, 1.296],
            [0.600, 0.817], [0.415, 0.888], [0.205, 0.984], [0.620, 0.810], [0.910, 0.725], [1.027, 0.696],
            [0.756, 0.767], [0.372, 0.907], [0.941, 0.717], [0.466, 0.867], [0.288, 0.944], [0.992, 0.705],
            [0.564, 0.831], [0.244, 0.965], [0.676, 0.791], [0.881, 0.732], [0.785, 0.759], [0.274, 0.952],
            [0.848, 0.742], [0.694, 0.786], [0.984, 0.707], [0.447, 0.875], [0.268, 0.955], [0.125, 1.025],
            [0.323, 0.929], [0.589, 0.821], [0.000, 1.539], [0.375, 0.905], [0.753, 0.767], [0.513, 0.850],
            [0.822, 0.748], [0.401, 0.895], [0.238, 0.968], [0.655, 0.798], [0.003, 1.190], [0.888, 0.730],
            [1.007, 0.702], [0.415, 0.890], [0.792, 0.756], [0.064, 1.057], [0.317, 0.931], [0.697, 0.785],
            [0.134, 1.020], [0.455, 0.871], [0.276, 0.950], [0.596, 0.818], [0.084, 1.047], [0.009, 1.134],
            [0.625, 0.810], [0.913, 0.723], [0.306, 0.936], [0.830, 0.746], [0.733, 0.773], [0.173, 1.000],
            [0.068, 1.055], [0.857, 0.738], [0.084, 1.051], [0.517, 0.847], [0.672, 0.793], [1.003, 0.702],
            [0.410, 0.890], [0.789, 0.758], [0.547, 0.836], [0.857, 0.739], [0.049, 1.065], [0.435, 0.880],
            [0.255, 0.960], [0.219, 0.977], [0.638, 0.804], [0.347, 0.917], [0.165, 1.004], [0.484, 0.860],
            [0.098, 1.039], [0.190, 0.991], [0.964, 0.711], [0.021, 1.087], [0.694, 0.787], [0.585, 0.822],
            [0.123, 1.025], [0.223, 0.975], [0.662, 0.796], [0.895, 0.729], [0.799, 0.755], [0.534, 0.841],
            [0.043, 1.069], [0.312, 0.935], [0.690, 0.787], [0.128, 1.024], [0.105, 1.035], [0.389, 0.900],
            [0.767, 0.763], [0.835, 0.744], [0.660, 0.798], [0.475, 0.865], [0.571, 0.827], [0.386, 0.900],
            [0.765, 0.765], [0.881, 0.732], [1.000, 0.703], [0.408, 0.892], [0.785, 0.758], [0.032, 1.075],
            [0.329, 0.926], [0.708, 0.781], [0.146, 1.013], [0.440, 0.880], [0.260, 0.958], [0.725, 0.776],
            [0.617, 0.811], [0.199, 0.989], [0.647, 0.801], [0.280, 0.948], [0.002, 1.256], [0.515, 0.848],
            [0.825, 0.747], [0.349, 0.917], [0.728, 0.775], [0.167, 1.003], [0.961, 0.712], [0.085, 1.045],
            [0.852, 0.739], [0.509, 0.850], [1.021, 0.699], [0.428, 0.883], [0.537, 0.840], [0.315, 0.932],
            [0.131, 1.021], [0.453, 0.872], [0.274, 0.951], [0.484, 0.860], [0.186, 0.993], [0.627, 0.808],
            [0.917, 0.723], [0.481, 0.861], [0.303, 0.939], [0.071, 1.053], [0.217, 0.980], [0.978, 0.708],
            [0.101, 1.037], [0.683, 0.789], [0.546, 0.836], [0.029, 1.081], [0.702, 0.783], [0.829, 0.747],
            [0.005, 1.153], [0.383, 0.902], [0.760, 0.765], [0.520, 0.847], [0.804, 0.753], [0.628, 0.808],
            [0.352, 0.916], [0.489, 0.859], [0.053, 1.065], [0.016, 1.103], [0.593, 0.820], [0.408, 0.892],
            [0.223, 0.975], [0.907, 0.727], [1.023, 0.697], [0.431, 0.881], [0.809, 0.752], [0.527, 0.846],
            [0.057, 1.061], [0.325, 0.927], [0.704, 0.783], [0.141, 1.016], [0.462, 0.869], [0.284, 0.946],
            [0.933, 0.720], [0.717, 0.779], [0.158, 1.009], [0.595, 0.818], [0.016, 1.131], [0.898, 0.728],
            [0.298, 0.939], [0.505, 0.852], [0.367, 0.908], [0.747, 0.770], [0.186, 0.994], [0.937, 0.718],
            [0.075, 1.051], [0.863, 0.737], [0.399, 0.899], [0.097, 1.040], [0.240, 0.967], [0.665, 0.796],
            [1.009, 0.701], [0.416, 0.887], [0.795, 0.756], [0.553, 0.834], [0.841, 0.742], [0.041, 1.070],
            [0.448, 0.874], [0.270, 0.954], [1.002, 0.703], [0.206, 0.984], [0.645, 0.801], [0.741, 0.773],
            [0.355, 0.914], [0.492, 0.857], [0.314, 0.933], [0.971, 0.710], [0.029, 1.083], [0.701, 0.785],
            [0.141, 1.020], [0.578, 0.825], [0.116, 1.029], [0.230, 0.972], [0.651, 0.799], [0.884, 0.731],
            [0.788, 0.758], [0.249, 0.965], [0.540, 0.838], [0.683, 0.790], [0.122, 1.029], [0.972, 0.709],
            [0.112, 1.031], [0.616, 0.811],
        ])
        self.classifiers = ['pseudoconstraint']

    def do_component_function(self, d, x):
        x1, x2 = x
        f1 = x1
        f2 = (1 + x2) * numpy.exp(-x1 / (1 + x2))
        if d == 0:
            f = f1
        else:
            f = f2
        penalty = (
            .5 * (numpy.tanh(8 * (1 - (f2 / (.858 * numpy.exp(-.541 * f1))))) + 1) +
            .5 * (numpy.tanh(8 * (1 - (f2 / (.728 * numpy.exp(-.295 * f1))))) + 1)
        )
        return f + penalty


class ConstrExModified(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(ConstrExModified, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = [[.1, 1], [0, 5]]
        self.min_loc = numpy.array([[0.58474974,  2.49998757], [-3, -1]])
        self.fmin = numpy.array([0.641940644438, 1.00247273569])
        self.fmax = numpy.array([2.13583713336, 61.5497968284])
        self.frontier = numpy.array([
            [0.741, 3.335], [0.880, 1.260], [0.652, 5.324], [0.706, 3.991], [0.757, 3.032], [0.816, 2.102],
            [0.867, 1.420], [0.645, 5.655], [0.668, 4.842], [0.707, 3.948], [0.675, 4.653], [0.767, 2.851],
            [0.827, 1.944], [0.697, 4.149], [0.911, 1.140], [0.744, 3.266], [0.803, 2.308], [0.729, 3.520],
            [0.778, 2.688], [0.838, 1.810], [0.760, 3.021], [0.821, 2.074], [0.867, 1.429], [0.787, 2.570],
            [0.761, 3.012], [0.932, 1.114], [0.685, 4.450], [0.874, 1.328], [0.648, 5.496], [0.792, 2.473],
            [0.718, 3.746], [0.682, 4.485], [0.741, 3.303], [0.801, 2.329], [0.718, 3.717], [0.733, 3.457],
            [0.658, 5.119], [0.701, 4.052], [0.948, 1.070], [0.665, 4.938], [0.766, 2.894], [0.825, 1.988],
            [0.735, 3.416], [0.877, 1.311], [0.652, 5.383], [0.691, 4.287], [0.754, 3.087], [0.813, 2.155],
            [0.721, 3.663], [0.790, 2.487], [0.851, 1.626], [0.886, 1.223], [0.861, 1.490], [0.643, 5.798],
            [0.667, 4.854], [0.714, 3.813], [0.657, 5.202], [0.687, 4.385], [0.738, 3.370], [0.797, 2.395],
            [0.776, 2.711], [0.836, 1.824], [0.744, 3.269], [0.653, 5.303], [0.694, 4.208], [0.852, 1.624],
            [0.855, 1.577], [0.764, 2.913], [0.824, 1.991], [0.871, 1.364], [0.647, 5.552], [0.673, 4.709],
            [0.876, 1.315], [0.712, 3.850], [0.757, 3.031], [0.688, 4.383], [0.746, 3.228], [0.805, 2.275],
            [0.785, 2.574], [0.845, 1.701], [0.665, 4.962], [0.855, 1.569], [0.642, 5.977], [0.793, 2.451],
            [0.699, 4.133], [0.896, 1.184], [0.661, 5.035], [0.833, 1.887], [0.677, 4.606], [0.686, 4.404],
            [0.810, 2.218], [0.967, 1.050], [0.721, 3.675], [0.655, 5.293], [0.710, 3.897], [0.848, 1.671],
            [0.757, 3.032], [0.817, 2.093], [0.646, 5.619], [0.672, 4.734], [0.704, 4.002], [0.681, 4.522],
            [0.773, 2.754], [0.833, 1.863], [0.693, 4.241], [0.730, 3.495], [0.783, 2.618], [0.843, 1.753],
            [0.658, 5.148], [0.694, 4.232], [0.871, 1.377], [0.646, 5.626], [0.755, 3.086], [0.881, 1.249],
            [0.652, 5.337], [0.680, 4.537], [0.746, 3.215], [0.806, 2.256], [0.715, 3.795], [0.779, 2.659],
            [0.840, 1.773], [0.733, 3.440], [0.659, 5.091], [0.703, 4.021], [0.864, 1.490], [0.993, 1.030],
            [0.768, 2.848], [0.828, 1.936], [0.666, 4.875], [0.651, 5.476], [0.675, 4.664], [0.767, 2.865],
            [0.827, 1.959], [0.737, 3.406], [0.748, 3.170], [0.808, 2.219], [0.726, 3.573], [0.788, 2.527],
            [0.848, 1.661], [0.751, 3.124], [0.812, 2.171], [0.866, 1.440], [0.644, 5.745], [0.655, 5.277],
            [0.691, 4.289], [0.926, 1.127], [0.738, 3.347], [0.798, 2.370], [0.724, 3.609], [0.771, 2.793],
            [0.832, 1.888], [0.657, 5.154], [0.700, 4.081], [0.859, 1.541], [0.853, 1.606], [0.762, 2.955],
            [0.822, 2.025], [0.674, 4.681], [0.710, 3.880], [0.763, 2.946], [0.822, 2.034], [0.748, 3.213],
            [0.642, 6.001], [0.720, 3.679], [0.785, 2.572], [0.845, 1.706], [0.699, 4.119], [0.860, 1.512],
            [0.643, 5.841], [0.794, 2.451], [0.893, 1.214], [0.662, 5.005],
        ])
        self.classifiers = ['pseudoconstraint']

    def do_component_function(self, d, x):
        x1, x2 = x
        if d == 0:
            f = x1
        else:
            f = (1 + x2) / x1
        penalty = .5 * (numpy.tanh(6 - (x2 + 9 * x1)) + 1) + .5 * (numpy.tanh(1 - (-x2 + 9 * x1)) + 1)
        return f + penalty


class BinhKornModified(MulticriteriaTestFunction):
    def __init__(self, dim=2, verify=True):
        assert dim == 2
        super(BinhKornModified, self).__init__(dim, verify)
        self.output_dim = 2
        self.bounds = [[0, 5], [0, 3]]
        self.min_loc = numpy.array([[0.58474974,  2.49998757], [-3, -1]])
        self.fmin = numpy.array([0.641940644438, 1.00247273569])
        self.fmax = numpy.array([2.13583713336, 61.5497968284])
        self.frontier = numpy.array([
            [10.761, 31.349], [55.434, 12.448], [0.900, 47.184], [6.317, 36.245], [44.957, 15.135], [72.406, 9.101],
            [41.408, 16.282], [17.327, 26.512], [51.015, 13.503], [1.722, 45.276], [3.683, 40.090], [30.749, 19.912],
            [22.644, 23.522], [6.582, 35.703], [14.342, 28.511], [63.494, 10.730], [33.842, 18.743], [25.622, 22.116],
            [40.789, 16.345], [112.692, 5.449], [53.882, 12.830], [2.100, 43.978], [5.691, 36.859], [20.242, 24.900],
            [61.312, 11.186], [82.977, 7.679], [8.081, 33.955], [56.663, 12.205], [39.057, 16.936], [25.735, 22.017],
            [42.078, 16.025], [5.211, 37.740], [58.293, 11.810], [3.155, 41.166], [89.118, 6.962], [9.916, 32.162],
            [45.208, 15.109], [19.868, 25.024], [67.454, 9.976], [8.427, 33.639], [35.750, 18.051], [6.059, 36.401],
            [32.846, 19.116], [49.091, 14.045], [6.630, 35.679], [44.801, 15.152], [47.943, 14.310], [4.052, 39.413],
            [31.937, 19.440], [11.706, 30.632], [7.743, 34.455], [2.506, 42.728], [12.398, 30.002], [59.141, 11.618],
            [48.269, 14.207], [18.057, 26.110], [36.363, 17.801], [2.001, 44.175], [27.988, 21.014], [24.212, 22.744],
            [68.376, 9.803], [81.754, 7.740], [7.855, 34.265], [16.248, 27.231], [35.976, 17.959], [10.982, 31.167],
            [27.539, 21.278], [5.577, 37.173], [1.537, 45.325], [41.593, 16.107], [31.033, 19.762], [93.871, 6.721],
            [18.519, 25.786], [9.382, 32.633], [12.799, 29.662], [123.528, 5.192], [60.134, 11.426], [43.915, 15.424],
            [59.066, 11.723], [73.930, 8.859], [18.072, 26.076], [54.283, 12.709], [2.149, 43.773], [66.318, 10.310],
            [11.326, 30.868], [47.766, 14.431], [21.504, 24.115], [7.199, 34.978], [38.017, 17.301], [15.297, 27.871],
            [65.590, 10.374], [33.110, 18.964], [97.463, 6.302], [49.420, 13.909], [23.753, 23.040], [15.118, 28.121],
            [40.417, 16.471], [108.367, 5.759], [4.884, 38.048], [29.739, 20.280], [63.456, 10.733], [85.799, 7.395],
            [8.881, 33.166], [3.138, 41.313], [55.012, 12.561], [37.692, 17.363], [26.318, 21.760], [19.366, 25.450],
            [38.510, 17.094], [55.976, 12.328], [29.858, 20.238], [21.976, 23.904], [71.295, 9.289], [12.547, 29.892],
            [59.579, 11.580], [5.960, 36.595], [48.734, 14.175], [2.711, 42.262], [77.096, 8.370], [44.738, 15.211],
            [19.639, 25.186], [50.127, 13.720], [4.689, 38.437], [33.693, 18.744], [131.242, 5.161], [7.929, 34.136],
            [13.922, 28.846], [62.503, 10.922], [46.229, 14.758], [39.235, 16.835], [118.153, 5.349], [56.875, 12.113],
            [2.539, 42.626], [66.629, 10.169], [25.836, 21.977], [0.540, 50.272], [22.228, 23.748], [64.935, 10.444],
            [81.039, 7.890], [7.579, 34.525], [15.859, 27.463], [5.425, 37.340], [35.796, 17.988], [28.159, 20.975],
            [10.096, 32.007], [6.113, 36.318], [43.376, 15.564], [3.911, 39.707], [31.382, 19.630], [93.934, 6.518],
            [43.372, 15.675], [18.610, 25.735], [65.137, 10.422], [9.437, 32.573], [11.755, 30.499], [57.758, 11.931],
            [47.054, 14.561], [21.048, 24.553], [60.351, 11.385], [70.588, 9.415], [40.000, 16.699], [16.467, 27.065],
            [51.442, 13.390], [3.790, 39.897], [11.154, 31.044], [22.923, 23.373], [6.453, 35.853], [14.155, 28.647],
            [63.131, 10.821], [35.152, 18.265], [101.395, 6.076], [51.917, 13.325], [26.769, 21.598], [38.873, 16.963],
            [51.612, 13.360], [5.049, 37.796], [30.233, 20.110], [63.734, 10.693], [85.851, 7.299], [8.934, 33.070],
            [24.315, 22.687], [41.931, 16.026], [16.839, 26.865], [58.266, 11.840], [2.975, 41.560], [28.257, 20.936],
            [88.139, 7.156], [9.596, 32.520], [20.535, 24.642], [68.738, 9.748], [8.876, 33.203], [36.698, 17.739],
            [14.494, 28.438], [6.011, 36.426], [10.693, 31.571], [76.929, 8.437], [6.560, 35.845], [44.474, 15.254],
            [49.575, 13.876], [1.532, 45.949], [4.486, 38.680], [33.259, 18.929], [12.519, 29.994], [20.430, 24.690],
            [2.805, 41.961], [12.397, 30.039], [59.067, 11.637], [0.700, 48.445], [102.900, 5.940], [24.920, 22.435],
            [48.187, 14.224], [16.861, 26.836], [61.879, 11.146], [37.294, 17.485], [15.031, 28.169], [54.510, 12.657],
            [2.164, 43.667], [28.801, 20.668], [24.967, 22.384], [66.652, 10.140], [78.460, 8.270], [6.859, 35.370],
            [14.764, 28.214], [36.059, 17.907], [11.080, 31.118], [27.722, 21.251], [5.483, 37.185], [41.509, 16.122],
            [32.530, 19.185], [96.514, 6.430], [18.461, 25.845], [9.359, 32.701], [32.399, 19.374], [11.791, 30.472],
            [57.855, 11.918], [22.628, 23.618], [44.855, 15.147], [3.450, 40.872], [75.159, 8.654], [18.663, 25.711],
            [52.682, 13.114], [1.981, 44.536], [3.270, 40.939], [29.378, 20.521], [10.117, 31.956], [47.746, 14.500],
            [21.400, 24.163], [7.125, 35.033], [15.187, 27.917], [65.350, 10.388], [33.229, 18.956], [49.564, 13.908],
            [25.134, 22.361], [16.197, 27.366], [42.267, 15.909], [108.452, 5.634], [4.990, 37.928], [28.485, 20.808],
            [21.621, 24.110], [63.801, 10.673], [8.970, 33.042], [56.538, 12.211], [1.164, 46.932], [38.952, 16.947],
            [27.368, 21.290], [9.336, 32.769], [18.406, 25.904], [68.930, 9.732], [38.611, 17.083], [15.719, 27.610],
            [56.084, 12.319], [3.457, 40.545], [29.937, 20.221], [91.240, 6.797], [10.587, 31.634], [21.341, 24.488],
            [46.441, 14.721], [20.797, 24.560], [69.057, 9.681], [13.461, 29.205], [61.609, 11.172], [6.575, 35.834],
            [34.070, 18.726], [12.666, 29.868], [2.618, 42.422], [74.253, 8.830], [1.726, 44.797], [42.560, 15.837],
            [18.255, 26.011], [49.778, 13.817], [4.553, 38.587], [33.419, 18.859], [132.368, 5.040], [20.425, 24.762],
            [7.328, 34.900], [2.330, 43.232], [12.976, 29.524], [60.512, 11.338], [105.490, 5.928], [23.414, 23.156],
            [46.078, 14.794], [16.831, 26.939], [37.401, 17.438], [54.654, 12.619], [2.191, 43.600], [4.027, 39.555],
            [27.191, 21.364], [23.479, 23.110], [67.106, 10.035], [83.485, 7.550], [8.282, 33.749], [16.912, 26.775],
            [34.286, 18.526], [26.847, 21.562], [26.312, 21.961], [75.719, 8.647], [6.198, 36.267], [43.514, 15.526],
            [19.033, 25.656], [3.679, 40.307], [30.350, 20.030], [19.398, 25.273], [66.646, 10.140], [9.985, 32.052],
            [11.833, 30.446], [119.791, 5.283], [57.889, 11.891], [1.292, 46.209], [7.048, 35.257], [45.336, 15.047],
            [10.423, 31.943], [72.857, 9.031], [17.548, 26.384], [53.373, 12.921], [4.255, 39.062], [12.036, 30.313],
            [22.904, 23.404], [76.870, 8.531], [6.411, 35.917], [14.078, 28.701], [62.923, 10.843], [34.974, 18.295],
            [51.704, 13.345], [24.627, 22.563], [39.570, 16.735], [52.434, 13.163], [1.883, 44.619], [5.278, 37.450],
            [30.840, 19.860], [61.128, 11.213], [82.885, 7.729], [8.032, 34.015], [25.640, 22.066], [43.698, 15.516],
            [5.131, 37.793], [40.277, 16.510], [58.124, 11.840], [3.004, 41.494], [28.405, 20.900], [88.191, 7.096],
            [9.619, 32.453], [20.614, 24.589], [68.936, 9.725], [34.569, 18.451], [13.294, 29.382], [5.654, 36.995],
            [31.793, 19.548], [47.789, 14.415], [78.916, 8.129], [7.111, 35.178], [45.991, 14.828], [48.059, 14.265],
            [4.101, 39.352], [32.020, 19.387],
        ])
        self.classifiers = ['pseudoconstraint']

    def do_component_function(self, d, x):
        x1, x2 = x
        if d == 0:
            f = 4 * x1 ** 2 + 4 * x2 ** 2
        else:
            f = (x1 - 5) ** 2 + (x2 - 5) ** 2
        penalty = .5 * (numpy.tanh(25 - ((x1 - 5) ** 2 + x2 ** 2)) + 1)
        return f + penalty
